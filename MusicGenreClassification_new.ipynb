{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNtPxppx+jieevGh0aRpTKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernando2393/DT2119-Final-Project/blob/master/MusicGenreClassification_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ARlMjf9rf7o",
        "colab_type": "code",
        "outputId": "9e941089-e49b-42f8-d60f-338858292eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVk4S0otr0VY",
        "colab_type": "code",
        "outputId": "90bc1519-c7d8-4148-f03e-9b5cb4da9894",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35c99e57-c9d5-43a1-9156-89680df35681\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-35c99e57-c9d5-43a1-9156-89680df35681\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving constants.py to constants (1).py\n",
            "Saving features.py to features (1).py\n",
            "Saving loader.py to loader (1).py\n",
            "Saving main.py to main (1).py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'constants.py': b'DATASETS = \"/content/drive/My Drive/Datasets/fma_small/\"\\r\\nMETADATA = \"/content/drive/My Drive/Datasets/fma_metadata/\"\\r\\nMFCC = \"/content/drive/My Drive/Datasets/mfcc.csv\"\\r\\nSPECTROGRAM = \"/content/drive/My Drive/Datasets/spectrogram.csv\"\\r\\n',\n",
              " 'features.py': b'import pandas as pd\\r\\nimport sklearn\\r\\nimport librosa.display\\r\\nimport librosa\\r\\nimport os\\r\\nfrom tqdm import tqdm\\r\\nimport warnings\\r\\nimport constants as cts\\r\\n\\r\\n\\r\\ndef compute_feature(mode, filepath):\\r\\n    \"\"\"\\r\\n    This method loads the a music track and computes the mfcc.\\r\\n    :param mode: allows to get either spectrogram or mfcc.\\r\\n    :param filepath: music track.\\r\\n    :return mfcc of the data track.\\r\\n    \"\"\"\\r\\n    y, sr = librosa.load(filepath, duration=28.5, sr=44100, mono=True, offset=0.5)  # Load 28 seconds\\r\\n    # (same length for every track)\\r\\n    if mode == \\'spectrogram\\':\\r\\n        spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\\r\\n        spectrogram = sklearn.preprocessing.scale(spectrogram, axis=1)  # Normalize spectrogram to have mean 0 and std 1\\r\\n\\r\\n        return spectrogram\\r\\n\\r\\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\\r\\n    mfcc = sklearn.preprocessing.scale(mfcc, axis=1)  # Normalize mfcc to have mean 0 and std 1\\r\\n\\r\\n    return mfcc\\r\\n\\r\\n\\r\\nclass FeatureComputation:\\r\\n\\r\\n    @staticmethod\\r\\n    def preprocessing(mode):\\r\\n        \"\"\"\\r\\n        This method parses the data files, calls compute_mfcc and save them into a .csv file.\\r\\n        \"\"\"\\r\\n        warnings.filterwarnings(\\'ignore\\')\\r\\n        folders = os.listdir(cts.DATASETS)\\r\\n        if \\'.DS_Store\\' in folders:  # MacOS file system check\\r\\n            folders.remove(\\'.DS_Store\\')\\r\\n        folders.sort()\\r\\n        feature_dict = {}\\r\\n        for foldername in tqdm(folders):\\r\\n            files = os.listdir(cts.DATASETS + foldername)\\r\\n            if \\'.DS_Store\\' in files:  # MacOS file system check\\r\\n                files.remove(\\'.DS_Store\\')\\r\\n            files.sort()\\r\\n            for file in files:\\r\\n                if os.path.isdir(cts.DATASETS + foldername):\\r\\n                    key = file.strip(\\'0\\')\\r\\n                    key = key.replace(\\'.mp3\\', \\'\\')\\r\\n                    feature = compute_feature(mode, cts.DATASETS + foldername + \\'/\\' + file)\\r\\n                    feature_dict[int(key)] = feature\\r\\n\\r\\n        df = pd.DataFrame(list(feature_dict.items()), columns=[\\'track\\', mode]).astype(object)\\r\\n        if mode == \\'spectrogram\\':\\r\\n            df.to_pickle(cts.SPECTROGRAM)\\r\\n        else:\\r\\n            df.to_pickle(cts.MFCC)\\r\\n\\r\\n',\n",
              " 'loader.py': b'\"\"\"\\r\\nThis class is in charge of loading the relevant data and splitting the dataset.\\r\\nnote: Check https://nbviewer.jupyter.org/github/mdeff/fma/blob/outputs/usage.ipynb for a deeper understanding of\\r\\n      the data format in the .csv files.\\r\\n\"\"\"\\r\\n\\r\\nimport pandas as pd\\r\\nimport features\\r\\nimport constants as cts\\r\\nfrom pathlib import Path\\r\\n\\r\\n\\r\\nclass Loader:\\r\\n    def __init__(self):\\r\\n        self.features = [\\'mfcc\\', \\'chroma_cens\\', \\'tonnetz\\', \\'spectral_contrast\\',\\r\\n                         [\\'spectral_centroid\\', \\'spectral_bandwidth\\', \\'spectral_rolloff\\'],\\r\\n                         [\\'rmse\\', \\'zcr\\']]  # Main categories of the stored features\\r\\n\\r\\n    @staticmethod\\r\\n    def load_echonest():\\r\\n        \"\"\"\\r\\n        This method loads the data echonest features from the .csv file.\\r\\n        :return echonest features of the data.\\r\\n        \"\"\"\\r\\n        echonest = pd.read_csv(cts.METADATA + \"echonest.csv\", index_col=0, header=[0, 1, 2])\\r\\n\\r\\n        return echonest\\r\\n\\r\\n    @staticmethod\\r\\n    def load_genres():\\r\\n        \"\"\"\\r\\n        This method loads the data genres from the .csv file.\\r\\n        :return genres of the data and top level genres.\\r\\n        \"\"\"\\r\\n        genres = pd.read_csv(cts.METADATA + \"genres.csv\", index_col=0)\\r\\n        top_level = genres[\\'top_level\\'].unique()  # This corresponds to the considered \"top-level genres\"\\r\\n\\r\\n        print(\"There is a total of \" + str(genres.shape[0]) + \" genres.\")\\r\\n        print(\"There is a total of \" + str(len(top_level)) + \" top-level genres.\")\\r\\n\\r\\n        return genres, top_level\\r\\n\\r\\n    @staticmethod\\r\\n    def load_tracks():\\r\\n        \"\"\"\\r\\n        This method loads the data tracks from the .csv file.\\r\\n        :return music tracks.\\r\\n        \"\"\"\\r\\n        tracks = pd.read_csv(cts.METADATA + \"tracks.csv\", index_col=0, header=[0, 1])\\r\\n\\r\\n        return tracks\\r\\n\\r\\n    @staticmethod\\r\\n    def load_features(mode):\\r\\n        if mode == \\'spectrogram\\':\\r\\n            if not Path(cts.SPECTROGRAM).is_file():  # Check if the file exists\\r\\n                print(\"Need to compute...\")\\r\\n                compute_ = features.FeatureComputation()\\r\\n                compute_.preprocessing(mode)  # If the file does not exist, create it\\r\\n            mfcc_val = pd.read_pickle(cts.SPECTROGRAM)\\r\\n\\r\\n        else:\\r\\n            if not Path(cts.MFCC).is_file():  # Check if the file exists\\r\\n                print(\"Need to compute...\")\\r\\n                compute_ = features.FeatureComputation()\\r\\n                compute_.preprocessing(mode)  # If the file does not exist, create it\\r\\n            mfcc_val = pd.read_pickle(cts.MFCC)\\r\\n\\r\\n        return mfcc_val\\r\\n\\r\\n    @staticmethod\\r\\n    def get_targets(tracks):\\r\\n        \"\"\"\\r\\n        This methods separates the tracks into dataset by means of the \\'cat\\' feature.\\r\\n        :param tracks: the music tracks loaded in the format returned by \\'load_tracks\\'.\\r\\n        :return training set, validation set and test set targets and tracks ID.\\r\\n        \"\"\"\\r\\n        train = tracks[\\'set\\', \\'split\\'] == \\'training\\'  # Training songs\\r\\n        val = tracks[\\'set\\', \\'split\\'] == \\'validation\\'  # Validation songs\\r\\n        test = tracks[\\'set\\', \\'split\\'] == \\'test\\'  # Test songs\\r\\n\\r\\n        y_train = tracks.loc[train, (\\'track\\', \\'genre_top\\')]\\r\\n        y_val = tracks.loc[val, (\\'track\\', \\'genre_top\\')]\\r\\n        y_test = tracks.loc[test, (\\'track\\', \\'genre_top\\')]\\r\\n\\r\\n        return y_train, y_val, y_test\\r\\n\\r\\n\\r\\ndef get_train_val_test(mode=\\'spectrogram\\'):\\r\\n    \"\"\"\\r\\n    :return training, validation and test datasets.\\r\\n    \"\"\"\\r\\n    loader = Loader()\\r\\n    print(\"Calculating \" + mode + \"...\")\\r\\n    mfcc_ = loader.load_features(mode)  # Load the features dataframe of the dataset songs.\\r\\n    tracks = loader.load_tracks()  # Load all the tracks of the big dataset.\\r\\n    y_train, y_val, y_test = loader.get_targets(tracks)  # Load the target values of all the tracks.\\r\\n    # Get training mfcc and labels dataframes.\\r\\n    mfcc_train = mfcc_.loc[mfcc_[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    y_train = y_train[mfcc_train[\\'track\\'].to_numpy()]\\r\\n    y_train = y_train[y_train.notna()]\\r\\n    mfcc_train = mfcc_train.loc[mfcc_train[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    # Get validation mfcc and labels dataframes.\\r\\n    mfcc_val = mfcc_.loc[mfcc_[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    y_val = y_val[mfcc_val[\\'track\\'].to_numpy()]\\r\\n    y_val = y_val[y_val.notna()]\\r\\n    mfcc_val = mfcc_val.loc[mfcc_val[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    # Get testing mfcc and labels dataframes.\\r\\n    mfcc_test = mfcc_.loc[mfcc_[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    y_test = y_test[mfcc_test[\\'track\\'].to_numpy()]\\r\\n    y_test = y_test[y_test.notna()]\\r\\n    mfcc_test = mfcc_test.loc[mfcc_test[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    # Get the mfcc values and convert them to numpy arrays.\\r\\n    x_train = mfcc_train[mode].to_numpy()\\r\\n    x_val = mfcc_val[mode].to_numpy()\\r\\n    x_test = mfcc_test[mode].to_numpy()\\r\\n    # Conver the target values to numpy arrays.\\r\\n    y_train = y_train.to_numpy()\\r\\n    y_val = y_val.to_numpy()\\r\\n    y_test = y_test.to_numpy()\\r\\n\\r\\n    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\\r\\n\\r\\n',\n",
              " 'main.py': b'import loader\\r\\n\\r\\n\\r\\ndef main():\\r\\n    (x_train, y_train), (x_val, y_val), (x_test, y_test) = loader.get_train_val_test(mode=\\'spectrogram\\')\\r\\n    print(\"There are the following classes:\")\\r\\n    classes = set(y_train.tolist()) & set(y_val.tolist()) & set(y_test.tolist())\\r\\n    print(classes)\\r\\n\\r\\n\\r\\nif __name__ == \"__main__\":\\r\\n    main()\\r\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeW8hEdTsfOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, ZeroPadding2D, ELU, Reshape, GRU\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4sgcgSFs7Yn",
        "colab_type": "code",
        "outputId": "87a7acf6-87e1-4026-aae1-5b6327348d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "import loader\n",
        "(x_train_prelim, y_train_prelim), (x_val_prelim, y_val_prelim), (x_test_prelim, y_test_prelim) = loader.get_train_val_test(mode=\"spectrogram\")\n",
        "print(\"There are the following classes:\")\n",
        "classes = set(y_train_prelim.tolist()) & set(y_val_prelim.tolist()) & set(y_test_prelim.tolist())\n",
        "print(classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating spectrogram...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b04e6a884daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train_prelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_prelim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val_prelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_prelim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test_prelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_prelim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_train_val_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spectrogram\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There are the following classes:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_prelim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_prelim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_prelim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/loader.py\u001b[0m in \u001b[0;36mget_train_val_test\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mmfcc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the features dataframe of the dataset songs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mtracks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tracks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load all the tracks of the big dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the target values of all the tracks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/loader.py\u001b[0m in \u001b[0;36mload_features\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mcompute_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeatureComputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mcompute_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# If the file does not exist, create it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mmfcc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPECTROGRAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycB9CBy43WZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove corrupted samples\n",
        "x_train_prelim = np.delete(x_train_prelim, 3495)\n",
        "x_train_prelim = np.delete(x_train_prelim, 3495)\n",
        "x_train_prelim = np.delete(x_train_prelim, 3495)\n",
        "y_train_prelim = np.delete(y_train_prelim, 3495)\n",
        "y_train_prelim = np.delete(y_train_prelim, 3495)\n",
        "y_train_prelim = np.delete(y_train_prelim, 3495)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0mH1Noo3Pgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "for i in range(6397 - 3):\n",
        "  x_train[i].append(x_train_prelim[i])\n",
        "del x_train_prelim\n",
        "\n",
        "x_val = []\n",
        "x_test = []\n",
        "\n",
        "for i in range(800):\n",
        "  x_val[i].append(x_val_prelim[i])\n",
        "  x_test[i].append(x_test_prelim[i])\n",
        "\n",
        "del x_val_prelim\n",
        "del x_test_prelim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE83ZDfEt-B8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape((6394, 13, 2455, 1))\n",
        "x_val = x_val.reshape((800, 13, 2455, 1))\n",
        "x_test = x_test.reshape((800, 13, 2455, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDaVTvLQ7gnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_labels = {'Electronic': 0, 'Experimental': 1, 'Folk': 2, 'Hip-Hop': 3,\n",
        "               'Instrumental': 4, 'International': 5, 'Pop': 6, 'Rock': 7}\n",
        "\n",
        "y_train = np.zeros([6397 - 3])\n",
        "y_val = np.zeros([800])\n",
        "y_test = np.zeros([800])\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "  y_train[i] = dict_labels[y_train_prelim[i]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3k2RLnh-m2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(y_val_prelim)):\n",
        "  y_val[i] = dict_labels[y_val_prelim[i]]\n",
        "  y_test[i] = dict_labels[y_test_prelim[i]]\n",
        "\n",
        "del y_train_prelim\n",
        "del y_val_prelim\n",
        "del y_test_prelim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpI0tKaQOGGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding of classes\n",
        "y_train = to_categorical(y_train, num_classes=8)\n",
        "y_val = to_categorical(y_val, num_classes=8)\n",
        "y_test = to_categorical(y_test, num_classes=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVkafgZB98EP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS_Csonw9-MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecU0Y2MM-4xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Classifier:\n",
        "    @staticmethod\n",
        "    def build(width, height, depth, classes):\n",
        "        \n",
        "        model = Sequential()\n",
        "        inputShape = (height, width, depth)\n",
        "\n",
        "        model.add(Conv2D(16, (3, 3), strides=(1, 1), input_shape=inputShape)) \n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "        \n",
        "        model.add(Conv2D(32, (3, 3), strides=(1, 1)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "        \n",
        "        model.add(Conv2D(64, (3, 3), strides=(1, 1)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
        "        model.add(Dropout(0.2))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(Dense(classes, activation='softmax'))\n",
        "        \n",
        "        print(\"summary\")\n",
        "        print(model.summary())\n",
        "        \n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32BE9v7z-753",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 25\n",
        "INIT_LR = 0.005\n",
        "BS = 16\n",
        "\n",
        "model = Classifier.build(width=2455, height=128, depth=1, classes=8)\n",
        "\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR/EPOCHS)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Callbacks: early stopping and checkpoint\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1, \n",
        "                               patience=10,\n",
        "                               mode='max',\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "filepath = \"weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "callbacks_list = [early_stopping, checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQhUggyt_PGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=BS,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                   steps_per_epoch=len(x_train) // BS,\n",
        "                    callbacks=callbacks_list,\n",
        "                    epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sshHyXn5Dv7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.pcolormesh(x_test_prelim[300])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}