{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of best_model.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyMIznvQljRxXZNTteX1dQU/",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bjelikj/Checkers/blob/master/final_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lsm-qRxkGJTp",
    "colab_type": "code",
    "outputId": "4c95aea3-3f6a-4bd0-8403-1c12a3677825",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qEzT0g7cGsjs",
    "colab_type": "code",
    "outputId": "ece67d6f-0814-4ac5-f3b0-ada1ca248a90",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "source": [
    "#!rm features.py\n",
    "#!rm constants.py\n",
    "#!rm load_csv_data.py\n",
    "#!rm loader.py\n",
    "!ls"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3hgpT66PGud1",
    "colab_type": "code",
    "outputId": "c919b346-c7b8-4f26-acdc-11545d5235a7",
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 269
    }
   },
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-0927a890-dc9e-4b35-bf7f-0688cd043821\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-0927a890-dc9e-4b35-bf7f-0688cd043821\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "Saving constants.py to constants.py\n",
      "Saving features.py to features.py\n",
      "Saving load_csv_data.py to load_csv_data.py\n",
      "Saving loader.py to loader.py\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'constants.py': b'# Run locally\\n\"\"\"\\nDATASETS = \"Datasets/fma_small/\"\\nMETADATA = \"Datasets/fma_metadata/\"\\nMFCC = \"Datasets/mfcc.csv\"\\nSPECTROGRAM = \"Datasets/spectrogram.csv\"\\nSPECTROGRAM_AUGMENT = \"Datasets/spectrogram_augment_6.csv\"\\nAUGMENT = True\\n\"\"\"\\n# # Run on Google Colab\\nDATASETS = \"/content/drive/My Drive/Datasets/fma_small/\"\\nMETADATA = \"/content/drive/My Drive/Datasets/fma_metadata/\"\\nMFCC = \"/content/drive/My Drive/Datasets/mfcc.csv\"\\nSPECTROGRAM = \"/content/drive/My Drive/Datasets/spectrogram.csv\"\\nSPECTROGRAM_AUGMENT = \"/content/drive/My Drive/Datasets/spectrogram_augment.csv\"\\n\\n\\n# spectrogram_augment_1.csv: time stretch, rate=1.1\\n# spectrogram_augment_2.csv: pitch shift, n_steps=2\\n# spectrogram_augment_3.csv: time stretch, rate=0.9\\n# spectrogram_augment_4.csv: sampling different 3s from dataset\\n# spectrogram_augment_5.csv: pitch shift, n_steps=-2\\n\\n\"\"\"\\nTODO:\\n    Try rectangular filters\\n    no augmentation on val and test\\n    add dropout, batchnormalization\\n\"\"\"',\n",
       " 'features.py': b'import pandas as pd\\r\\nimport sklearn\\r\\nimport librosa.display\\r\\nimport librosa\\r\\nimport os\\r\\nfrom tqdm import tqdm\\r\\nimport warnings\\r\\nimport constants as cts\\r\\nimport numpy as np\\r\\n\\r\\n\\r\\ndef compute_feature(mode, filepath):\\r\\n    \"\"\"\\r\\n    This method loads the a music track and computes the mfcc.\\r\\n    :param mode: allows to get either spectrogram or mfcc.\\r\\n    :param filepath: music track.\\r\\n    :return mfcc of the data track.\\r\\n    \"\"\"\\r\\n    if mode == \\'spectrogram\\':\\r\\n        y, sr = librosa.load(filepath, duration=3.5, mono=True, offset=15.5)  # Load 10 seconds\\r\\n        stft = np.abs(librosa.stft(y, n_fft=2048, hop_length=604))\\r\\n        mel = librosa.feature.melspectrogram(n_mels=128, sr=sr, S=stft ** 2)\\r\\n        log_mel = librosa.power_to_db(mel, ref=np.max)\\r\\n\\r\\n        return log_mel\\r\\n\\r\\n    y, sr = librosa.load(filepath, duration=28.5, sr=44100, mono=True, offset=0.5)  # Load 28 seconds\\r\\n    # (same length for every track)\\r\\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\\r\\n    mfcc = sklearn.preprocessing.scale(mfcc, axis=1)  # Normalize mfcc to have mean 0 and std 1\\r\\n\\r\\n    return mfcc\\r\\n\\r\\n\\r\\ndef augment_feature(filepath, rate=0.8, n_steps=2.0, effect=\"time_stretch\"):\\r\\n    \"\"\"\\r\\n    This method loads the a music track and augments it.\\r\\n    :param effect: applied augmentation effect.\\r\\n    :param n_steps: steps taken.\\r\\n    :param rate: sampling rate.\\r\\n    :param filepath: music track.\\r\\n    :return log mel-spectogram of the data track.\\r\\n    \"\"\"\\r\\n    y, sr = librosa.load(filepath, duration=3.5, mono=True, offset=21.5)\\r\\n\\r\\n    if effect == \"time_stretch\":\\r\\n        y_changed = librosa.effects.time_stretch(y, rate=rate)\\r\\n    if effect == \"pitch_shift\":\\r\\n        y_changed = librosa.effects.pitch_shift(y, sr, n_steps=n_steps)\\r\\n    else: y_changed = y\\r\\n\\r\\n    stft = np.abs(librosa.stft(y_changed, n_fft=2048, hop_length=604))\\r\\n    mel = librosa.feature.melspectrogram(n_mels=128, sr=sr, S=stft ** 2)\\r\\n    log_mel = librosa.power_to_db(mel, ref=np.max)\\r\\n\\r\\n    return log_mel\\r\\n\\r\\n\\r\\nclass FeatureComputation:\\r\\n\\r\\n    @staticmethod\\r\\n    def preprocessing(mode):\\r\\n        \"\"\"\\r\\n        This method parses the data files, calls compute_mfcc and save them into a .csv file.\\r\\n        \"\"\"\\r\\n        warnings.filterwarnings(\\'ignore\\')\\r\\n        folders = os.listdir(cts.DATASETS)\\r\\n        if \\'.DS_Store\\' in folders:  # MacOS file system check\\r\\n            folders.remove(\\'.DS_Store\\')\\r\\n        folders.sort()\\r\\n        feature_dict = {}\\r\\n        for foldername in tqdm(folders):\\r\\n            files = os.listdir(cts.DATASETS + foldername)\\r\\n            if \\'.DS_Store\\' in files:  # MacOS file system check\\r\\n                files.remove(\\'.DS_Store\\')\\r\\n            files.sort()\\r\\n            for file in files:\\r\\n                if os.path.isdir(cts.DATASETS + foldername):\\r\\n                    key = file.strip(\\'0\\')\\r\\n                    key = key.replace(\\'.mp3\\', \\'\\')\\r\\n                    if cts.AUGMENT:\\r\\n                        feature = augment_feature(cts.DATASETS + foldername + \\'/\\' + file, rate=1.1,\\r\\n                                                  effect=None)\\r\\n                        feature_dict[int(key)] = feature\\r\\n                    else:\\r\\n                        feature = compute_feature(mode, cts.DATASETS + foldername + \\'/\\' + file)\\r\\n                        feature_dict[int(key)] = feature\\r\\n        df = pd.DataFrame(list(feature_dict.items()), columns=[\\'track\\', mode]).astype(object)\\r\\n        if mode == \\'spectrogram\\' and cts.AUGMENT:\\r\\n            df.to_pickle(cts.SPECTROGRAM_AUGMENT)\\r\\n        elif mode == \\'spectrogram\\':\\r\\n            df.to_pickle(cts.SPECTROGRAM)\\r\\n        else:\\r\\n            df.to_pickle(cts.MFCC)\\r\\n\\r\\n',\n",
       " 'load_csv_data.py': b'from loader import Loader\\r\\nimport pandas as pd\\r\\n\\r\\ndef load_features(filepath):\\r\\n    return pd.read_pickle(filepath)\\r\\n\\r\\ndef get_train_val_test(filepath):\\r\\n    \"\"\"\\r\\n    :return training, validation and test datasets.\\r\\n    \"\"\"\\r\\n    loader = Loader()\\r\\n    mfcc_ = load_features(filepath)  # Load the features dataframe of the dataset songs.\\r\\n    tracks = loader.load_tracks()  # Load all the tracks of the big dataset.\\r\\n    y_train, y_val, y_test = loader.get_targets(tracks)  # Load the target values of all the tracks.\\r\\n    \\r\\n    # Get training mfcc and labels dataframes.\\r\\n    mfcc_train = mfcc_.loc[mfcc_[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    y_train = y_train[mfcc_train[\\'track\\'].to_numpy()]\\r\\n    y_train = y_train[y_train.notna()]\\r\\n    mfcc_train = mfcc_train.loc[mfcc_train[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    # Get validation mfcc and labels dataframes.\\r\\n    mfcc_val = mfcc_.loc[mfcc_[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    y_val = y_val[mfcc_val[\\'track\\'].to_numpy()]\\r\\n    y_val = y_val[y_val.notna()]\\r\\n    mfcc_val = mfcc_val.loc[mfcc_val[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    # Get testing mfcc and labels dataframes.\\r\\n    mfcc_test = mfcc_.loc[mfcc_[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    y_test = y_test[mfcc_test[\\'track\\'].to_numpy()]\\r\\n    y_test = y_test[y_test.notna()]\\r\\n    mfcc_test = mfcc_test.loc[mfcc_test[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    # Get the mfcc values and convert them to numpy arrays.\\r\\n    x_train = mfcc_train[\\'spectrogram\\'].to_numpy()\\r\\n    x_val = mfcc_val[\\'spectrogram\\'].to_numpy()\\r\\n    x_test = mfcc_test[\\'spectrogram\\'].to_numpy()\\r\\n    # Convert the target values to numpy arrays.\\r\\n    y_train = y_train.to_numpy()\\r\\n    y_val = y_val.to_numpy()\\r\\n    y_test = y_test.to_numpy()\\r\\n\\r\\n    return (x_train, y_train), (x_val, y_val), (x_test, y_test)',\n",
       " 'loader.py': b'\"\"\"\\r\\nThis class is in charge of loading the relevant data and splitting the dataset.\\r\\nnote: Check https://nbviewer.jupyter.org/github/mdeff/fma/blob/outputs/usage.ipynb for a deeper understanding of\\r\\n      the data format in the .csv files.\\r\\n\"\"\"\\r\\n\\r\\nimport pandas as pd\\r\\nimport features\\r\\nimport constants as cts\\r\\nfrom pathlib import Path\\r\\n\\r\\n\\r\\nclass Loader:\\r\\n    def __init__(self):\\r\\n        self.features = [\\'mfcc\\', \\'chroma_cens\\', \\'tonnetz\\', \\'spectral_contrast\\',\\r\\n                         [\\'spectral_centroid\\', \\'spectral_bandwidth\\', \\'spectral_rolloff\\'],\\r\\n                         [\\'rmse\\', \\'zcr\\']]  # Main categories of the stored features\\r\\n\\r\\n    @staticmethod\\r\\n    def load_echonest():\\r\\n        \"\"\"\\r\\n        This method loads the data echonest features from the .csv file.\\r\\n        :return echonest features of the data.\\r\\n        \"\"\"\\r\\n        echonest = pd.read_csv(cts.METADATA + \"echonest.csv\", index_col=0, header=[0, 1, 2])\\r\\n\\r\\n        return echonest\\r\\n\\r\\n    @staticmethod\\r\\n    def load_genres():\\r\\n        \"\"\"\\r\\n        This method loads the data genres from the .csv file.\\r\\n        :return genres of the data and top level genres.\\r\\n        \"\"\"\\r\\n        genres = pd.read_csv(cts.METADATA + \"genres.csv\", index_col=0)\\r\\n        top_level = genres[\\'top_level\\'].unique()  # This corresponds to the considered \"top-level genres\"\\r\\n\\r\\n        print(\"There is a total of \" + str(genres.shape[0]) + \" genres.\")\\r\\n        print(\"There is a total of \" + str(len(top_level)) + \" top-level genres.\")\\r\\n\\r\\n        return genres, top_level\\r\\n\\r\\n    @staticmethod\\r\\n    def load_tracks():\\r\\n        \"\"\"\\r\\n        This method loads the data tracks from the .csv file.\\r\\n        :return music tracks.\\r\\n        \"\"\"\\r\\n        tracks = pd.read_csv(cts.METADATA + \"tracks.csv\", index_col=0, header=[0, 1])\\r\\n\\r\\n        return tracks\\r\\n\\r\\n    @staticmethod\\r\\n    def load_features(mode, filename):\\r\\n        if mode == \\'spectrogram\\':\\r\\n            if Path(\"Datasets/\" + filename + \".csv\").is_file():  # Check if specific data exists\\r\\n                spectrogram = pd.read_pickle(\"Datasets/\" + filename + \".csv\")\\r\\n\\r\\n                return spectrogram\\r\\n            if not Path(cts.SPECTROGRAM).is_file():  # Check if the file exists\\r\\n                compute_ = features.FeatureComputation()\\r\\n                compute_.preprocessing(mode)  # If the file does not exist, create it\\r\\n            spectrogram = pd.read_pickle(cts.SPECTROGRAM)\\r\\n\\r\\n            return spectrogram\\r\\n        else:\\r\\n            if not Path(cts.MFCC).is_file():  # Check if the file exists\\r\\n                compute_ = features.FeatureComputation()\\r\\n                compute_.preprocessing(mode)  # If the file does not exist, create it\\r\\n            mfcc = pd.read_pickle(cts.MFCC)\\r\\n\\r\\n            return mfcc\\r\\n\\r\\n    @staticmethod\\r\\n    def get_targets(tracks):\\r\\n        \"\"\"\\r\\n        This methods separates the tracks into dataset by means of the \\'cat\\' feature.\\r\\n        :param tracks: the music tracks loaded in the format returned by \\'load_tracks\\'.\\r\\n        :return training set, validation set and test set targets and tracks ID.\\r\\n        \"\"\"\\r\\n        train = tracks[\\'set\\', \\'split\\'] == \\'training\\'  # Training songs\\r\\n        val = tracks[\\'set\\', \\'split\\'] == \\'validation\\'  # Validation songs\\r\\n        test = tracks[\\'set\\', \\'split\\'] == \\'test\\'  # Test songs\\r\\n\\r\\n        y_train = tracks.loc[train, (\\'track\\', \\'genre_top\\')]\\r\\n        y_val = tracks.loc[val, (\\'track\\', \\'genre_top\\')]\\r\\n        y_test = tracks.loc[test, (\\'track\\', \\'genre_top\\')]\\r\\n\\r\\n        return y_train, y_val, y_test\\r\\n\\r\\n\\r\\ndef process_data(mfcc_, y):\\r\\n    mfcc = mfcc_.loc[mfcc_[\\'track\\'].isin(y.index[:].tolist())]\\r\\n    y = y[mfcc[\\'track\\'].to_numpy()]\\r\\n    y = y[y.notna()]\\r\\n    mfcc_train = mfcc.loc[mfcc[\\'track\\'].isin(y.index[:].tolist())]\\r\\n\\r\\n    return mfcc_train, y\\r\\n\\r\\n\\r\\ndef get_train_val_test(mode=\\'spectrogram\\', filename=\"\"):\\r\\n    \"\"\"\\r\\n    :return training, validation and test datasets.\\r\\n    \"\"\"\\r\\n    loader = Loader()\\r\\n    print(\"Calculating \" + mode + \"...\")\\r\\n    mfcc_ = loader.load_features(mode, filename)  # Load the features dataframe of the dataset songs.\\r\\n    tracks = loader.load_tracks()  # Load all the tracks of the big dataset.\\r\\n    y_train, y_val, y_test = loader.get_targets(tracks)  # Load the target values of all the tracks.\\r\\n    # Get training mfcc and labels dataframes.\\r\\n    mfcc_train, y_train = process_data(mfcc_, y_train)\\r\\n    # Get validation mfcc and labels dataframes.\\r\\n    mfcc_val, y_val = process_data(mfcc_, y_val)\\r\\n    # Get testing mfcc and labels dataframes.\\r\\n    mfcc_test, y_test = process_data(mfcc_, y_test)\\r\\n    # Get the mfcc values and convert them to numpy arrays.\\r\\n    x_train = mfcc_train[mode].to_numpy()\\r\\n    x_val = mfcc_val[mode].to_numpy()\\r\\n    x_test = mfcc_test[mode].to_numpy()\\r\\n    # Conver the target values to numpy arrays.\\r\\n    y_train = y_train.to_numpy()\\r\\n    y_val = y_val.to_numpy()\\r\\n    y_test = y_test.to_numpy()\\r\\n\\r\\n    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\\r\\n'}"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dcgoALAnGvvG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import loader\n",
    "import load_csv_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wtUB95F9Gx0b",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Load original dataset\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram.csv\")\n",
    "\n",
    "# Load augmented dataset (pitch shift, n_steps=2)\n",
    "(x_train_aug_2, y_train_aug_2), (x_val_aug_2, y_val_aug_2), (x_test_aug_2, y_test_aug_2) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_2.csv\")\n",
    "\n",
    "# Load augmented dataset (time stretch, rate=0.9)\n",
    "(x_train_aug_3, y_train_aug_3), (x_val_aug_3, y_val_aug_3), (x_test_aug_3, y_test_aug_3) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_3.csv\")\n",
    "\n",
    "# Load augmented dataset (different 3s of tracks sampled)\n",
    "(x_train_aug_4, y_train_aug_4), (x_val_aug_4, y_val_aug_4), (x_test_aug_4, y_test_aug_4) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_4.csv\")\n",
    "\n",
    "# Load augmented dataset (pitch shift, n_steps=-2)\n",
    "(x_train_aug_5, y_train_aug_5), (x_val_aug_5, y_val_aug_5), (x_test_aug_5, y_test_aug_5) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_5.csv\")\n",
    "\n",
    "# Load augmented dataset (different 3s, time stretch, rate=1.1)\n",
    "(x_train_aug_6, y_train_aug_6), (x_val_aug_6, y_val_aug_6), (x_test_aug_6, y_test_aug_6) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_6.csv\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UpMyoTWpDYDv",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Stack datasets\n",
    "x_train = np.hstack((x_train, x_train_aug_2, x_train_aug_3, x_train_aug_4, x_train_aug_5, x_train_aug_6))\n",
    "y_train = np.hstack((y_train, y_train_aug_2, y_train_aug_3, y_train_aug_4, y_train_aug_5, y_train_aug_6))\n",
    "#x_val = np.hstack((x_val, x_val_aug_4))\n",
    "#x_test = np.hstack((x_test, x_test_aug_4))\n",
    "#y_val = np.hstack((y_val, y_val_aug_4))\n",
    "#y_test = np.hstack((y_test, y_test_aug_4))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4nLHDJEQG1tW",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "x_train = np.rollaxis(np.dstack(x_train), -1)\n",
    "x_val = np.rollaxis(np.dstack(x_val), -1)\n",
    "x_test = np.rollaxis(np.dstack(x_test), -1)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fJyqk1OVmMyA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_val = np.expand_dims(x_val, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n0dmg67nz7DA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "dict_labels = {'Electronic': 0, 'Experimental': 1, 'Folk': 2, 'Hip-Hop': 3,\n",
    "                   'Instrumental': 4, 'International': 5, 'Pop': 6, 'Rock': 7}\n",
    "y_train = [dict_labels[y_train[i]] for i in range(y_train.shape[0])]\n",
    "y_val = [dict_labels[y_val[i]] for i in range(y_val.shape[0])]\n",
    "y_test = [dict_labels[y_test[i]] for i in range(y_test.shape[0])]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VYlZiNIr1Is2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "y_train = to_categorical(y_train, num_classes=8)\n",
    "y_val = to_categorical(y_val, num_classes=8)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=8)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8Yv5v9cUG7YC",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def plot_history(history):\n",
    "\n",
    "    fig, axs = plt.subplots(2)\n",
    "    # create accuracy sublpot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy eval\")\n",
    "    # create error sublpot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"validation error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error eval\")\n",
    "    plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E27nHIQiG-DF",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def build_model(input_shape):\n",
    "  X_input = layers.Input(input_shape)\n",
    "\n",
    "  X = layers.Conv2D(32, (5, 5), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
    "  X = layers.BatchNormalization()(X)\n",
    "  X = layers.Activation('relu')(X)\n",
    "\n",
    "  X1 = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
    "  X1 = layers.BatchNormalization()(X1)\n",
    "\n",
    "  b1 = layers.MaxPool2D((2, 2))(X) \n",
    "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "  b1 = layers.BatchNormalization()(b1)\n",
    "  b1 = layers.Activation('relu')(b1)\n",
    "  b1 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "  b1 = layers.BatchNormalization()(b1)\n",
    "\n",
    "  X = layers.Add()([X1, b1])\n",
    "  X = layers.Activation('relu')(X)\n",
    "\n",
    "  X1 = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
    "  X1 = layers.BatchNormalization()(X1)\n",
    "\n",
    "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "  b1 = layers.BatchNormalization()(b1)\n",
    "  b1 = layers.Activation('relu')(b1)\n",
    "  b1 = layers.Conv2D(128, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "  b1 = layers.BatchNormalization()(b1)\n",
    "\n",
    "  X = layers.Add()([X1, b1])\n",
    "  X = layers.Activation('relu')(X)\n",
    "\n",
    "  X2 = layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
    "  X2 = layers.BatchNormalization()(X2)\n",
    "\n",
    "  b2 = layers.MaxPool2D((2, 2))(X) \n",
    "  b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
    "  b2 = layers.BatchNormalization()(b2)\n",
    "  b2 = layers.Activation('relu')(b2)\n",
    "  b2 = layers.Conv2D(256, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
    "  b2 = layers.BatchNormalization()(b2)\n",
    "\n",
    "\n",
    "  X = layers.Add()([X2, b2])\n",
    "  X = layers.Activation('relu')(X)\n",
    "\n",
    "  X2 = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
    "  X2 = layers.BatchNormalization()(X2)\n",
    "\n",
    "  b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
    "  b2 = layers.BatchNormalization()(b2)\n",
    "  b2 = layers.Activation('relu')(b2)\n",
    "  b2 = layers.Conv2D(128, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
    "  b2 = layers.BatchNormalization()(b2)\n",
    "\n",
    "  X = layers.Add()([X2, b2])\n",
    "  X = layers.Activation('relu')(X)\n",
    "\n",
    "  X3 = layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
    "  X3 = layers.BatchNormalization()(X3)\n",
    "\n",
    "  b3 = layers.MaxPool2D((2, 2))(X) \n",
    "  b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
    "  b3 = layers.BatchNormalization()(b3)\n",
    "  b3 = layers.Activation('relu')(b3)\n",
    "  b3 = layers.Conv2D(64, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
    "  b3 = layers.BatchNormalization()(b3)\n",
    "\n",
    "\n",
    "  X = layers.Add()([X3, b3])\n",
    "  X = layers.Activation('relu')(X)\n",
    "\n",
    "  X3 = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
    "  X3 = layers.BatchNormalization()(X3)\n",
    "\n",
    "  b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
    "  b3 = layers.BatchNormalization()(b3)\n",
    "  b3 = layers.Activation('relu')(b3)\n",
    "  b3 = layers.Conv2D(128, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
    "  b3 = layers.BatchNormalization()(b3)\n",
    "\n",
    "\n",
    "\n",
    "  X = layers.Flatten()(X)\n",
    "  X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
    "  X = layers.BatchNormalization()(X)\n",
    "  X = layers.Activation('relu')(X)\n",
    "  X = layers.Dense(8, kernel_initializer='he_uniform')(X)\n",
    "  X = layers.BatchNormalization()(X)\n",
    "  X = layers.Activation('softmax')(X)\n",
    "\n",
    "  model = tf.keras.models.Model(inputs=X_input, outputs=X, name='model_8')\n",
    "  model.summary()\n",
    "\n",
    "  return model"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sup8kMGlCbtI",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "2ab3a34f-f4af-4fd6-a0ce-5674011ca04a"
   },
   "source": [
    "lr = 2e-4\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "\n",
    "model = build_model((128, 128, 1))\n",
    "opt = Adam(lr=lr, decay=lr / epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "#model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Callbacks: early stopping and checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1,\n",
    "                               patience=7,\n",
    "                               mode='max',\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "filepath = \"/content/drive/My Drive/Models/weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "callbacks_list = [early_stopping, checkpoint]\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    steps_per_epoch=len(x_train) // batch_size,\n",
    "                    callbacks=callbacks_list,\n",
    "                    epochs=epochs, verbose=1)\n",
    "\n",
    "\n",
    "plot_history(history)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 64, 32)   832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 64, 32)   128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 64, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 32, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   528         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   18496       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   1040        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 128)  73856       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 128)  2176        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 128)  0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   4128        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 256)  8448        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 256)  295168      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   8224        batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 128)  295040      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 128)  4224        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 128)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 64)     8256        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 64)     73792       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     4160        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 64)     0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          524416      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            1032        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8)            32          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8)            0           batch_normalization_20[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 1,331,336\n",
      "Trainable params: 1,328,120\n",
      "Non-trainable params: 3,216\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "1347/1348 [============================>.] - ETA: 0s - loss: 0.3099 - accuracy: 0.4134\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.49375, saving model to /content/drive/My Drive/Models/weights.01-0.49.hdf5\n",
      "1348/1348 [==============================] - 23s 17ms/step - loss: 0.3099 - accuracy: 0.4134 - val_loss: 0.2740 - val_accuracy: 0.4938\n",
      "Epoch 2/30\n",
      "1347/1348 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.4979\n",
      "Epoch 00002: val_accuracy did not improve from 0.49375\n",
      "1348/1348 [==============================] - 22s 17ms/step - loss: 0.2772 - accuracy: 0.4978 - val_loss: 0.2830 - val_accuracy: 0.4875\n",
      "Epoch 3/30\n",
      "1348/1348 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.5563\n",
      "Epoch 00003: val_accuracy did not improve from 0.49375\n",
      "1348/1348 [==============================] - 22s 16ms/step - loss: 0.2541 - accuracy: 0.5563 - val_loss: 0.3061 - val_accuracy: 0.4575\n",
      "Epoch 4/30\n",
      "1346/1348 [============================>.] - ETA: 0s - loss: 0.2262 - accuracy: 0.6274\n",
      "Epoch 00004: val_accuracy improved from 0.49375 to 0.51500, saving model to /content/drive/My Drive/Models/weights.04-0.51.hdf5\n",
      "1348/1348 [==============================] - 23s 17ms/step - loss: 0.2262 - accuracy: 0.6272 - val_loss: 0.2764 - val_accuracy: 0.5150\n",
      "Epoch 5/30\n",
      "1347/1348 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.7007\n",
      "Epoch 00005: val_accuracy did not improve from 0.51500\n",
      "1348/1348 [==============================] - 22s 16ms/step - loss: 0.1948 - accuracy: 0.7007 - val_loss: 0.2985 - val_accuracy: 0.4675\n",
      "Epoch 6/30\n",
      "1348/1348 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.7721\n",
      "Epoch 00006: val_accuracy did not improve from 0.51500\n",
      "1348/1348 [==============================] - 23s 17ms/step - loss: 0.1641 - accuracy: 0.7721 - val_loss: 0.3131 - val_accuracy: 0.4775\n",
      "Epoch 7/30\n",
      "1347/1348 [============================>.] - ETA: 0s - loss: 0.1400 - accuracy: 0.8246\n",
      "Epoch 00007: val_accuracy did not improve from 0.51500\n",
      "1348/1348 [==============================] - 22s 16ms/step - loss: 0.1400 - accuracy: 0.8247 - val_loss: 0.3110 - val_accuracy: 0.4688\n",
      "Epoch 8/30\n",
      "1347/1348 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.8580\n",
      "Epoch 00008: val_accuracy did not improve from 0.51500\n",
      "1348/1348 [==============================] - 22s 16ms/step - loss: 0.1210 - accuracy: 0.8580 - val_loss: 0.3259 - val_accuracy: 0.4688\n",
      "Epoch 9/30\n",
      "1346/1348 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.8798\n",
      "Epoch 00009: val_accuracy did not improve from 0.51500\n",
      "1348/1348 [==============================] - 22s 16ms/step - loss: 0.1059 - accuracy: 0.8798 - val_loss: 0.3454 - val_accuracy: 0.4325\n",
      "Epoch 10/30\n",
      "1348/1348 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.8941\n",
      "Epoch 00010: val_accuracy did not improve from 0.51500\n",
      "1348/1348 [==============================] - 22s 17ms/step - loss: 0.0960 - accuracy: 0.8941 - val_loss: 0.3289 - val_accuracy: 0.4512\n",
      "Epoch 11/30\n",
      "1346/1348 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 0.9019Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.51500\n",
      "1348/1348 [==============================] - 22s 16ms/step - loss: 0.0888 - accuracy: 0.9018 - val_loss: 0.3353 - val_accuracy: 0.4387\n",
      "Epoch 00011: early stopping\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3zV1f3/n+/czJtFBhBIAomCEBJ2GDIURQRUlogLB3yr1GqrdtjaViut+qutlFKto2oBbcVRFNyIKBSRUaYYhswACdmQkD3uPb8/zifJTUggQG5uQs7z8fg8Put8zuf9yXi/znmfJUopDAaDwdB+8fK0AQaDwWDwLEYIDAaDoZ1jhMBgMBjaOUYIDAaDoZ1jhMBgMBjaOUYIDAaDoZ1jhMBgaAeIyBgRSfO0HYbWiRECQ5tCRNaIyEkR8fO0LQbDxYIRAkObQUTigNGAAia38Lu9W/J9BkNLYoTA0Ja4C9gILAbudr0hIrEi8r6I5IhInoj83eXevSKyR0QKRWS3iAyyrisR6eGSbrGIPGUdjxGRNBH5lYhkAotEJExEPrbecdI6jnF5PlxEFonIcev+cut6iohMcknnIyK5IjKwoY8UkRtEZIeI5IvIehHpZ13/lYgsrZf2byLynHU82+U7D4nID8/rp2xodxghMLQl7gLetLbxItIZQERswMfAESAOiAbetu7NAOZaz4agaxJ5TXxfFBAOdAfmoP9fFlnn3YBS4O8u6f8F2IFEoBPwV+v6G8AdLumuAzKUUtvrv9ASh4XAD4EI4B/Ah1Yo7G3gOhEJdvnum4El1uPZwA3Wd84G/lotegbDGVFKmc1srX4DRgGVQKR1vhf4qXV8OZADeDfw3OfAQ43kqYAeLueLgaes4zFABeB/BpsGACet4y6AEwhrIF1XoBAIsc6XAr9sJM+XgCfrXfseuNI6XgfcZR2PAw6ewb7l1d9ufU+ap3+PZmudm6kRGNoKdwMrlVK51vkSasNDscARpVRVA8/FAgfP8505Sqmy6hMRsYvIP0TkiIicAtYCHaySeSxwQil1sn4mSqnjwDfAdBHpAExE12oaojvwcysslC8i+VbeXa37S4DbrOPbqa0NICITRWSjiJywnrsOiDzPbze0I0wDmKHVIyIB6BCIzYrXA/ihnXB/4BjQTUS8GxCDY8CljWRdgg7lVBMFuHaxrD8178+BXsAwpVSmiAwAtgNivSdcRDoopfIbeNfrwD3o/7kNSqn0Rmw6BjytlHq6kfv/Af5itU1MQ9eGsEJH76FDYB8opSqtNgppJB+DoQZTIzC0BaYCDqAPOhwzAEgAvkY7vv8BGcAzIhIoIv4iMtJ69jXgFyIyWDQ9RKS7dW8HcLuI2ERkAnDlWewIRrcL5ItIOPBE9Q2lVAbwGfCi1ajsIyJXuDy7HBgEPIRuM2iMV4H7RGSYZW+giFxf3S6glMoB1qDbKg4rpfZYz/mixTEHqBKRicC1Z/kegwEwQmBoG9wNLFJKHVVKZVZv6IbamehS7ySgB3AUXaq/BUAp9R/gaXQIpRDtkMOtfB+ynsu38ll+FjsWAAFALrr30op69+9Et2PsRTfcPlx9QylVii6xxwPvN/YCpdQW4F7r204CB4BZ9ZItAa7BJSyklCoEHgTetZ67HfjwLN9jMAAgSpmFaQyGlkBEfgdcppS646yJDYYWxLQRGAwtgBVK+gG61mAwtCpMaMhgcDMici+6EfgzpdRaT9tjMNTHhIYMBoOhnWNqBAaDwdDOaXNtBJGRkSouLs7TZhgMBkObYuvWrblKqY4N3WtzQhAXF8eWLVs8bYbBYDC0KUTkSGP3TGjIYDAY2jlGCAwGg6Gd0+ZCQwaDwdBWcDgVJRVVlFQ4KC6vt7eul5RXUVzhoKSiiuJya+9yvbQ6bbmDX07oxY2DYs7+4nPECIHBYDA0gNOpyC+tJK+onNyiCnKLyskrKie/tLJxx16u99XOu6zS2eT32byEQF8bgX7e2F32HYP96O5rJ9DXmy6hAW75ViMEBoOh3VBSUUVejVOvIK/Y1cnrc32/ghPF5TgbGWYV4GMj0M+G3bfWaQf5edM52B+7rw27n41AX2/svt416Wr2vjbslpO3+1rp/Gz42rwQ8cxksUYIDAZDm6XK4eRkSeVpjj2vEUdfWuloMJ8gP28ig3yJCPKjW7idgd3C9HmgvhYR5EtkkB8Rgb50sPti87q4Zvc2QmAwGFotZZUOjp0o4eiJEmtfytETJaSdLCG7sJyTJRU0NDmCt5cQEeRLRKAfkcF+XBIZqM8tZx5pOffqc38fW8t/XCvCCIHBYPAYTqciq7CMY5aDr3b41c4/u7C8Tnq7r41u4XZiwuwkx4VZDt2PSNeSe6AfIQHeHguztEWMEBgMBrdSWFZZ4+iPnSjh2MmSGqefdrKUiqraBlUvgS6hAXQLtzOmV0e6hduJDbfTzdrCA32Ng3cDRggMBsMFUeVwklFQVlOKr1OyP1nKieKKOumD/b3pHmGnd1Qw4/p0Jjas1tF37RCAr7cZ3tTSGCEwGAxNJq+onO/SC0hJL2BnWgF7MwtJzy/F4dK9xttLiA7TpfoJ0aE1Tr7a4YfafTz4BYaGMEJgMBga5ERxhYvTzycl/RTp+aU19+MjA+kbE8qk/l3qhHCiQvzxtplSfVvCCIHBYCC/RDv9nWm1pX1Xpx8XYWdgtw7cPaI7SdGhJEWHEuJvSvYXC0YIDIZ2RkFJpXb66fmkpBfwXXoBx07UOv3uEXYGdOvAXZd3p290KInRoYQGGKd/MWOEwGC4iCkoqSTluHb236Xp/dETJTX3Y8MD6BfdgduHdqdfTChJXUNNDL8dYoTAYLhIKCitZJdVwt9pxfaP5NU6/ZiwAPrFhHLr0Fj6RofSNzqUDnZfD1psaC0YITAY2iilFQ7W7s9h5a4sth45QaqL04/uEEDf6FBuTq51+mGBxukbGsYIgcHQhigorWT13mxWpGTy3305lFY6CPH3ZvglEdw0OIa+MR3oGx1KuHH6hnPArUIgIhOAvwE24DWl1DP17ncDXgc6WGkeVUp96k6bDIa2RnZhGV/szuLzXVlsOJhLpUPRMdiP6YOjGZ8YxfBLIvAx3TUNF4DbhEBEbMALwDggDdgsIh8qpXa7JHsMeFcp9ZKI9AE+BeLcZZPB0FY4mlfC57sy+XxXJluPnkQp3Ztn9sh4xidGMTC2A14X2QyYBs/hzhrBUOCAUuoQgIi8DUwBXIVAASHWcShw3I32GAytFqUU32cV8nlKFit2ZbIn4xQACV1CeGhsT8YnRtE7KtjMs2NwC+4UgmjgmMt5GjCsXpq5wEoR+QkQCFzjRnsMhlaF06nYkZbP5ym65J+aV4IIDOoWxm+vS2B8YhTdIuyeNtPQDvB0Y/FtwGKl1F9E5HLgXyKSpJSqs76biMwB5gB069bNA2YaDM1DpcPJpkMnWLErg5W7ssguLMfbS7j80gjuGX0J1/bpTKcQf0+baWhnuFMI0oFYl/MY65orPwAmACilNoiIPxAJZLsmUkq9ArwCkJyc3MjicQZD66S6m+fnuzL5ck82BaWV+Pt4ceVlHZmQFMXVvTqbQVwGj+JOIdgM9BSReLQA3ArcXi/NUWAssFhEEgB/IMeNNhkMLUJj3TyvSejMtYlRXHlZRwJ82/eqWIbWg9uEQClVJSI/Bj5Hdw1dqJTaJSJ/ALYopT4Efg68KiI/RTccz1KqoYXnDIbWj2s3z/UHcqlymm6ehraBtDW/m5ycrLZs2eJpMwwGQPf22XjoBIu+OcyqPVk4rW6e4xOjTDdPQ6tCRLYqpZIbunfWGoGITAI+qd+AazC0Z8oqHSzfns7i9anszSwkzO7DnCsuZcqArqabp6HN0ZTQ0C3AAhF5Dx3e2etmmwyGVsvx/FL+tfEIb/3vKPkllfSOCubP0/sxeUBX/H1MzN/QNjmrECil7hCREKyuniKigEXAW0qpQncbaDB4GqUUW46cZPE3qazYlYlSinF9OjN7ZDzD4sNN6d/Q5mlSY7FS6pSILAUCgIeBacAjIvKcUup5dxpoMHiKskoHH+/MYPH6w6SknyLE35t7RsVzx/DuxIabgV6Gi4emtBFMBmYDPYA3gKFKqWwRsaOnizBCYLioyDpVxpsbj/DmpqPkFVfQs1MQT09LYtrAaOy+nh6DaTA0P035q54O/FUptdb1olKqRER+4B6zDIaWZ/vRkyz6JpVPv8vAoRRje3di1oh4RvaIMOEfw0VNU4RgLpBRfSIiAUBnpVSqUupLdxlmMLQEFVVOPv0ug0XrU/n2WD7Bft7cdXkcd4/oTveIQE+bZzC0CE0Rgv8AI1zOHda1IW6xyGBoAXIKy1my6Sj/3nSEnMJyLokM5PeTE5k+OIYgPxP+MbQvmvIX762Uqqg+UUpViIhZ/sjQJvkurYBF6w/z8bcZVDicXHlZR2bdFMeVPTuagV+GdktThCBHRCZbU0IgIlOAXPeaZTA0H5UOJ5/vymTxN6lsOXISu6+N24bGcteIOC7tGORp8wwGj9MUIbgPeFNE/g4Ieo2Bu9xqlcHQDJworuCt/x3l3xuPkFFQRrdwO4/f0IcZyTGE+JvZPg2GapoyoOwgMFxEgqzzIrdbZTBcAHsyTrH4m1SW70invMrJqB6RPDkliat6d8Jmwj8Gw2k0qVVMRK4HEgH/6m50Sqk/uNEug+GccDoVX+3N5rV1h9h46AT+Pl5MHxzDrBFxXNY52NPmGQytmqYMKHsZsANXAa8BNwH/c7NdBkOTKKmo4r1t6Sxcd5jDucV0DfXn0Ym9uXVILB3spk+DwdAUmlIjGKGU6iciO5VSvxeRvwCfudswg+FMZJ0q440Nqby5SU/+1j8mlOduG8jEpCgz57/BcI40RQjKrH2JiHQF8oAu7jPJYGiclPQCFq47zEc7j1PlVIzvE8U9o+MZ3D3MjP41GM6TpgjBRyLSAXgW2IZeSexVt1plMLhQHf//57rDbDiUh93Xxsxh3Zk9Ms6M/jUYmoEzCoGIeAFfKqXygfdE5GPAXylV0CLWGdo11fH/ResOcyi3mC6h/vx6Ym9uHdqN0ADT/dNgaC7OKARKKaeIvAAMtM7LgfKWMMzQfqkf/+9n4v8Gg1tpSmjoSxGZDrxvFpY3uJOG4v8/GB1Pson/GwxupSlC8EPgZ0CViJShRxcrpVSIWy0ztAucTsXq77N57WsT/zcYPEVTRhab0TiGZqe0wsHSbWkm/m8wtAKaMqDsioau11+oxmBoCg3F//926wCu69vFxP8NBg/RlNDQIy7H/sBQYCtwtVssMlyU7DpewD/XHeajb3X8/9o+nbln9CUm/m8wtAKaEhqa5HouIrHAArdZZLhoMPF/g6FtcD5LMaUBCc1tiOHiwfT/NxjaFk1pI3gePZoYwAsYgB5hbDDU4diJEt7YkMo7m49xqqzKxP8NhjZCU2oEW1yOq4C3lFLfuMkeQxtDKcX6g3ks+iaVL/dm4SXCxKQoZo2IM/P/GAxthKYIwVKgTCnlABARm4jYlVIlZ3tQRCYAfwNswGtKqWcaSHMzMBdd6/hWKXX7Odhv8BAlFVW8vy2d19ensj+7iIhAXx4Y04OZw7vRJTTA0+YZDIZzoEkji4FrgOqVyQKAlcCIMz0kIjbgBWAcul1hs4h8qJTa7ZKmJ/BrYKRS6qSIdDr3TzC0JEfzrPDPlmMUllWRFB3CvBn9uaFfF/x9bJ42z2AwnAdNEQJ/1+UplVJFImJvwnNDgQNKqUMAIvI2MAXY7ZLmXuAFpdRJK+/sJltuaDGUUnxzII/F6w/z5d5sbCJMSIpi9sg4BnUz4R+Doa3TFCEoFpFBSqltACIyGChtwnPR6IXuq0kDhtVLc5mV5zfo8NFcpdSK+hmJyBxgDkC3bt2a8GpDc1BcXsX729N5wyX88+OrejBzWHeiQv09bZ7BYGgmmiIEDwP/EZHj6HmGooBbmvH9PYExQAywVkT6WtNe16CUegV4BSA5OdlMfOdm6od/+kaH8pcZ/bnehH/aLZWVlaSlpVFWVnb2xAaP4u/vT0xMDD4+Te+q3ZQBZZtFpDfQy7r0vVKqsgl5pwOxLucx1jVX0oBNVn6HRWQfWhg2NyF/QzPSUPhnYt8uzBoRx6BuHUz4p52TlpZGcHAwcXFx5m+hFaOUIi8vj7S0NOLj45v8XFPGETwAvKmUSrHOw0TkNqXUi2d5dDPQU0Ti0QJwK1C/R9By4DZgkYhEokNFh5psveGCqQ7/vL4+lQNW+OcnV/Vg5vDudA4x4R+DpqyszIhAG0BEiIiIICcn55yea0po6F6l1AvVJ1bvnnuBMwqBUqpKRH4MfI6O/y9USu0SkT8AW5RSH1r3rhWR3YADeEQplXdOX2A4L47kFfPGhiO8Wy/8c0P/Lvh5m/CP4XSMCLQNzuf31BQhsImIVC9KY3UL9W1K5kqpT4FP6137ncuxQq918LMmW2w4b5RSrDuQy+JvUvnqexP+MRgMmqYIwQrgHRH5h3X+Q+Az95lkaG6Ky6t4f1sar284woHsIiKDTPjH0LbIz89nyZIl3H///ef87HXXXceSJUvo0KGDGyy7OGiKEPwK3XXzPut8J7rnkKGVcyC7iLf+d7Qm/NMvJpT5N+vePyb8Y2hL5Ofn8+KLLzYoBFVVVXh7N+7KPv3000bveRKlFEopvLw8Pw/XWS1QSjmBTUAqepDY1cAe95plOF8yC8p4de0hrn/ua66Z/19eX5/KVb068f79I/jggZHcOCjGiIChzfHoo49y8OBBBgwYwCOPPMKaNWsYPXo0kydPpk+fPgBMnTqVwYMHk5iYyCuvvFLzbFxcHLm5uaSmppKQkMC9995LYmIi1157LaWlpw+J+uijjxg2bBgDBw7kmmuuISsrC4CioiJmz55N37596devH++99x4AK1asYNCgQfTv35+xY8cCMHfuXObNm1eTZ1JSEqmpqaSmptKrVy/uuusukpKSOHbsGD/60Y9ITk4mMTGRJ554ouaZzZs3M2LECPr378/QoUMpLCzkiiuuYMeOHTVpRo0axbfffnvBP99GZVRELkP36LkNyAXeAVBKXXXBbzU0KwUllXyWksEHO46z8XAeSkH/mFAev6EPk/p3oVOwCf8Ymo/ff7SL3cdPNWuefbqG8MSkxEbvP/PMM6SkpNQ4wTVr1rBt2zZSUlJqukkuXLiQ8PBwSktLGTJkCNOnTyciIqJOPvv37+ett97i1Vdf5eabb+a9997jjjvuqJNm1KhRbNy4ERHhtdde489//jN/+ctfePLJJwkNDeW7774D4OTJk+Tk5HDvvfeydu1a4uPjOXHixFm/df/+/bz++usMHz4cgKeffprw8HAcDgdjx45l586d9O7dm1tuuYV33nmHIUOGcOrUKQICAvjBD37A4sWLWbBgAfv27aOsrIz+/fs3/QfdCGcKDe0FvgZuUEodABCRn17wGw3NQlmlg6/2ZrN8ezprvs+hwuEkPjKQh8b2ZHL/rlzSMcjTJhoMbmXo0KF1+so/99xzLFu2DIBjx46xf//+04QgPj6eAQMGADB48GBSU1NPyzctLY1bbrmFjIwMKioqat6xatUq3n777Zp0YWFhfPTRR1xxxRU1acLDw89qd/fu3WtEAODdd9/llVdeoaqqioyMDHbv3o2I0KVLF4YMGQJASEgIADNmzODJJ5/k2WefZeHChcyaNeus72sKZxKCG9F9/1eLyArgbfTIYoOHcDgV6w/m8sGO43yekklheRWdgv248/LuTBnQlb7Roabnj8HtnKnk3pIEBtaucrdmzRpWrVrFhg0bsNvtjBkzpsFR0H5+fjXHNputwdDQT37yE372s58xefJk1qxZw9y5c8/ZNm9vb5xOZ825qy2udh8+fJh58+axefNmwsLCmDVr1hlHb9vtdsaNG8cHH3zAu+++y9atW8/ZtgbtbeyGUmo5sFxEAtGTxT0MdBKRl4BlSqmVzWKB4YwopdiZVsDyHel8vDODnMJygv28mZAUxdSB0Qy/JAKbl3H+houb4OBgCgsLG71fUFBAWFgYdrudvXv3snHjxvN+V0FBAdHR0QC8/vrrNdfHjRvHCy+8wIIFeqXekydPMnz4cO6//34OHz5cExoKDw8nLi6Ojz/+GIBt27Zx+PDhBt916tQpAgMDCQ0NJSsri88++4wxY8bQq1cvMjIy2Lx5M0OGDKGwsJCAgAC8vb255557mDRpEqNHjyYsLOy8v9OVpkwxUQwsAZaISBgwA92TyAiBGzmUU8QHO47z4bfHOZxbjK/Ni6t7d2LKgK5c1buTmfPH0K6IiIhg5MiRJCUlMXHiRK6//vo69ydMmMDLL79MQkICvXr1qhN6OVfmzp3LjBkzCAsL4+qrr65x4o899hgPPPAASUlJ2Gw2nnjiCW688UZeeeUVbrzxRpxOJ506deKLL75g+vTpvPHGGyQmJjJs2DAuu+yyBt/Vv39/Bg4cSO/evYmNjWXkyJEA+Pr68s477/CTn/yE0tJSAgICWLVqFUFBQQwePJiQkBBmz5593t9YH7HGibUZkpOT1ZYtW86esA2SfaqMj3Zm8MGOdHamFSACl18SwdQB0YxPijLr/Ro8xp49e0hIMEuVtwaOHz/OmDFj2Lt3b6NdTxv6fYnIVqVUckPpz2fxekMzcqqskhUpmXy44zjrD+biVNA3OpTHrk9gUv+ubW/AV3Ee7F4OB7+Cjr2h57UQkwxepgZjMFwob7zxBr/97W+ZP39+s44/MELgAcoqHaz5PocPdqTz5d5sKqqcdI+w8+OrdY+fHp3aWI+f8kLY+wl8txQOrQZnFYREw/efwdfzwL8D9BgLPcZBj2sgqKOnLTYY2iR33XUXd911V7Pna4SghXA4FZsO5fHBjuN8mpJBYVkVkUG+3D60G1MHRtM/po31+Kksg/0rIWUp7PscqsogNBYufwCSboKovlCWDwdXw4FVsP8LSNEDcOg6UNcUeoyD6EGmtmAweBgjBG4mu7CMf647zPLt6WSdKifIz5vxiVFMGdCVEZdG4G3z/PDyJuOogsNr4Lv3YO/HUH4K7JEw8E7oexPEDAXX6mpAGCTdqDenEzJ3akE48AWsfRb++ycICNe1hZ7XwqVjITCi0dcbDAb30H6EYNu/YMML4BMAPnbw8a899va3rgXU2xq7V329+tgP6pXm84rKeWXtIV7fkEqlQ3F1705MHRDN2IQ21uPH6YRjm3TJf9dyKMkFvxBImARJ0yH+SrA14c/Iywu6DtDblY9AyQndjrD/C11j+O4/gED0YOg5Tm9dBtYVFoPB4BbajxDYwyGyB1SW6q3khHVcosMa1cfOqvPIXGpEwmnz52SlN1mlwjjly40hwcR2isDeqSc4EiE3CSJ7aSFqrSilS+/fLYWU9+FUmha+yybokn+PcRduvz1c59X3Ji02Gdth/yodblrzDKz5o65t9LhGi8KlV+tnDAZDs9N+hKD39Xo7G47KWrGoKq0ViMqyesJRUpuuspTysiL2HM0mNSMXb2cZ3UO86BPmhZ0KKE6HLV/r/ADEBpGXQedEiEqCzkn6OLjLaTWLFiX3gC75f7cU8vaDl7d2wGN/B72vA79g97zXy0vXBKIHw5hf6Z5HB7/UtYX9K2Hn2yBeEJ2sQ0g9r4Go/qa20I64kGmoARYsWMCcOXOw2+3NbNnFgRlHcIEUlVex+JvDvLL2EKfKqpiQGMXD43rSOyqkbkKnA04cgqwUyEyBrF36uOBYbZqAcEsc+up950TomODe2kNBmi71pyyFjG8BgbhROuzTZ4rnS+FOBxzfrgVh/xdwfJu+HtjJpbZwlW6PaLZ3OnX7R/kpKCuAMmvvel5ecPq9imIdKvQL0uEz3yAtnn7W3jfYOm/oWhD4BLZacfP0OILU1FRuuOEGUlJSzuv5uLg4tmzZQmRkZDNb1nTONl12c2LGEbQQpRUO3tiQyj/WHuJEcQXXJHTi4WsuIyk6tOEHvGwQ2VNvidNcMsqH7N2WOFjblkV1aw8RPayaQyJ0tkQipOv51x6Kc3Vf/+/eg6Pr9bWug2D8/9O2hXQ9v3zdgZdNj0OISYarfgNFOVZtYSV8/yl8u0T/jGKHWsJwrf4Z13He+ZbzPoNjdz0vLwTOUkDyDgD/UPAPsfYd9M+tshTKi6D4MFQU6rzKC5sYcpTTxcMv2LoW4iIeLveqz739zp79hVDlr7/rNJO9dEFF3CtgrtNQjxs3jmeffZZnn32Wd999l/LycqZNm8bvf/97iouLufnmm0lLS8PhcPD444+TlZXF8ePHueqqq4iMjGT16tV18v7DH/7ARx99RGlpKSNGjOAf//gHIsKBAwe47777yMnJwWaz8Z///IdLL72UP/3pT/z73//Gy8uLiRMn8swzzzBmzBjmzZtHcnIyubm5JCcnk5qayuLFi3n//fcpKirC4XDwySefMGXKFE6ePEllZSVPPfUUU6ZMAfQYgXnz5iEi9OvXjxdffJF+/fqxb98+fHx8OHXqFP379685b06MEJwjZZUO3tx0lJfWHCS3qJwrL+vIT8ddxoDY81z9KKADdB+ht2qcDjhxuFYYsnZB2uba7pegS8DVIaXqfacE3VbRoOGndF//lKW6S6dy6AFfVz2me/VEXHp+9rc0QR2h/616czogfWttbeGrJ/V2NsRLO2+/aiceCuHxLuch9e6H1E3rFwLeTVqtVaMUVJVDRZFV0yjUTrW80OVaI+flhVCUXXtcXqh/dy3N+HchzxLH9c9D3gGXm6J/pl42vRebVUg5h4JKVF+Y+Eyjt+tPQ71y5Ur279/P//73P5RSTJ48mbVr15KTk0PXrl355JNPAD1vUGhoKPPnz2f16tUN1gh+/OMf87vf6RV077zzTj7++GMmTZrEzJkzefTRR5k2bRplZWU4nU4+++wzPvjgAzZt2oTdbm/StNPbtm1j586dhIeHU1VVxbJlywgJCSE3N5fhw4czefJkdu/ezVNPPcX69euJjIzkxIkTBAcHM2bMGD755BOmTp3K22+/zY033tjsIgBGCJpMeZWDdzYf44XVB8g6Vc6ISyN4+Y5BJMe5IXTiZdMN25E9IHFq7fWyAsjaXRnletAAACAASURBVCsQmSmw7Q3dXgH6nzCih4s4JOn2jJT3tLOsKoPQbjDyQd3Xv3OiZ9skLhQvqyYQOxSufgwKs3RtoTDTcuYdGnbuvoEt+90iVi81fwi8wNCEUvr36CoM5YXgrGweWxujOAzCrcKCfwddI9IGgXJqUXZUUluTEksYbDrcJTaac/LilStXsnLlSgYOHAjoRWP279/P6NGj+fnPf86vfvUrbrjhBkaPHn3WvFavXs2f//xnSkpKOHHiBImJiYwZM4b09HSmTdO1d39/HZ5dtWoVs2fPrmlraMq00+PGjatJp5TiN7/5DWvXrsXLy4v09HSysrL46quvmDFjRo1QVae/5557+POf/8zUqVNZtGgRr7766jn+pJqGEYKzUOlwsnRrGn//6gDp+aUMiQtjwS0DufxSD/R39w+F7pfrrRqnE04erq05ZKZA+jbYtaw2TWAnGHS31dd/SNt2/mciuDMMuN3TVrgXqe2hRlCnlnvvnj1aTAFumN9wGuW0OlUUQ0WJbjNxlNfe9w7QIuxr1+0hDXS7bipKKX7961/zwx/+8LR727Zt49NPP+Wxxx5j7NixNaX9higrK+P+++9ny5YtxMbGMnfu3DNOA229/LRLrtNO13/eddrpN998k5ycHLZu3YqPjw9xcXFnfN/IkSNJTU1lzZo1OBwOkpKSzmzbeWKEoBGqHE6WbU/nua/2c+xEKQNiO/DM9L6M6hHZukYAe3npsE7Epbpxt5qyAsjeo2PTscOb1tffYLgQxEs7eV87VPs+R5UlDJY4lJ7QY1FA1xJchcHXrnuqNUD9aajHjx/P448/zsyZMwkKCiI9PR0fHx+qqqoIDw/njjvuoEOHDrz22mt1nq8fGqp2wpGRkRQVFbF06VJuunEqwb4Q0zWK5W8tYurEsZSXFOKoKGfc4B78Yf4LzLxmAPbAIE4UFBEeEUlcl0i2rvuSoQndWbpksRbF8iJwVOhjpUCEgoICOnXqhI+PD6tXr+bIkSMAXH311UybNo2f/exnRERE1ExnDXpaidtvv53HH3+8mX5Rp2O8Qz0cTsVH3x7nb1/u53BuMX2jQ/nDrCTG9OrYugTgbPiHQrfzn4rXYGgWbN5gs9pWoDa0VVGsQ5oVxVDosuxl9QBO30C9efuDyGnTUD/77LPs2bOHyy/XteOgoCD+/e9/c+DAAR555BG8vLzw8fHhpZdeAmDOnDlMmDCBrl2iWP35J9pBOyrpQAX33nETSQm9iOoUwZDES6A4B/IO8K/5j/PDXz3F7578Iz4+Pvxn4QtMuP4Gduw7RvJ1M/H18eG6sVfw/37zML+Yczs3//AXvLLwda4fO0oXwPL2w6kMKMmDjB0gNmaOG8ykfy2ib59eJA/oR+/LekBRDonxcfz2kYe58orR2GzeDBw4gMWLFoOXFzNnzuSxxx7jtttuc9uvyXQftXA6FZ+lZLJg1T72ZxfROyqYn467jGv7dG5bAmAwuAG3dh91OuoKQ0VxbYO4eNUVBh872BpoLFVKt5M4KmucvN5XH1c23I4iNp2fzbfhvZfvuXXpdTqsrap2U9Xn9a5Xnytn4/mJF0s/+YoPPl/Nv16arztL+DfSM9EF0330HFFKsXJ3Fn/9Yh97Mwvp0SmIF24fxMSkKLzMyl8Gg/vxslmN+VYbhFK6baG6naGyGIqyatPbfHUoCbSjrxaA+l1+xavWmfv7632Nk6929M083YuXzcrzXHqVOeuJRO3xT37+az5btZpP33pNC4qbCu7tVgiUUqz5Pof5X+zju/QC4iMD+dutA7ihX1ez9KPB4ElEdEjI2792QKPTYY3ir25vKNLpbL66pmBrwMnXdGNt5YgX2LwarOk8/8qiFjGh3QmBUop1B3KZ/8U+th/NJzY8gGdv6se0gdFtayZQg6GFUUp5LkzqZbMG1LWxtTo8wPmE+9uVEGw4mMdfv9jH/1JP0DXUnz/e2JebBsfgYwTAYDgj/v7+5OXlERERYdrMWjFKKfLy8mrGPTQVtwqBiEwA/gbYgNeUUg0OHRSR6cBSYIhSyi0TCf39q/3MW7mPziF+PDklkZuHxOLn3YamgzYYPEhMTAxpaWnk5OR42hTDWfD39ycmJuacnnGbEIiIDXgBGAekAZtF5EOl1O566YKBh4BN7rIFYEJSFwJ8vZk5rFvbWg/AYGgF+Pj4EB8f72kzDG7CnTGRocABpdQhpVQF8DYwpYF0TwJ/As4ynO/C6NEpiB+MijciYDAYDPVwpxBEAy5zLJNmXatBRAYBsUqpT86UkYjMEZEtIrLFVE0NBoOhefFYK6mIeAHzgZ+fLa1S6hWlVLJSKrljx47uN85gMBjaEe5sLE4HYl3OY6xr1QQDScAaqxdCFPChiEw+U4Px1q1bc0XkyHnaFAnknuezbRXzze0D883tgwv55u6N3XDbFBMi4g3sA8aiBWAzcLtSalcj6dcAv3BXryHrHVsaG2J9sWK+uX1gvrl94K5vdltoSClVBfwY+BzYA7yrlNolIn8Qkcnueq/BYDAYzg23jiNQSn0KfFrvWoOTgyulxrjTFoPBYDA0THsbUvuKpw3wAOab2wfmm9sHbvnmNjcNtcFgqGlT+7dS6jVP22Jo+7S3GoGhHSEiqSJSKiJFLtvfPW2XwdDaaFeTzhnaJZOUUqvOlkhEvK0ODq7XbEpVr5Byds41vcHQWmg3NQIRmSAi34vIARF51NP2uBsRiRWR1SKyW0R2ichDnrapJRARm4hsF5GPz5Juloh8IyJ/FZE8YK6ILBaRl0TkUxEpBq4SkQQRWSMi+dbPcbJLHqelb+A9oSLyTxHJEJF0EXnKstHPyjPJJW1HqwbTSUTCRORjEckRkZPW8WkziYlIBxFZKiJ7RWSPiFx+QT/ANoCI/NT6XaSIyFsicm5TbbYBRGShiGSLSIrLtXAR+UJE9lv7sOZ6X7sQApcJ8CYCfYDbRKSPZ61yO1XAz5VSfYDhwAPt4JtBT2C4p4lphwGHgM7A09a1263jYPREiB8BK4FOwE+AN0Wkl0serunXNfCOxejfRQ9gIHAtcI9Sqhx4H3BdiPZm4L9KqWz0/+Yi9CCgbkAp0FBY62/ACqVUb6D/OXx7m0REooEHgWSlVBJ6ZuNbPWuVW1gMTKh37VHgS6VUT+BL67xZaBdCQNMnwLtoUEplKKW2WceFaAcRfean2jZWifl6wLUBdblV8q7e7nW5d1wp9bxSqkopVWpd+0Ap9Y1SygkMAIKAZ5RSFUqpr4CPqeu8a9IrpepMnCginYHrgIeVUsWWg/8rtY5rCXWd2O3WNZRSeUqp95RSJdbv72ngynqfHABcAfzTeqZCKZXf1J9XG8YbCLAGrdqB4x62p9lRSq0FTtS7PAV43Tp+HZjaXO9rL20EDU2AN8xDtrQ4IhKHLo26darvVsAC4Jfo0nk1U8/QRnDsLNe6AscsUajmCHUFtaE8qukO+AAZLou5eLk8sxqwi8gwIAstPMsARMSOFo0JQHUIILheO0QkkAMsEpH+wFbgIaVU8RlsatMopdJFZB5wFF1LWqmUWulhs1qKzkqpDOs4E12TbRbaS42g3SIiQcB76FLpKU/b4y5E5AYgWym19Rwea6jvtOu140CsNUFiNd2oO2fWmfpfHwPKgUilVAdrC1FKJQJYDv1ddA3jNuBjq/QPejLGXsAwpVQIuuQP4Lo8mBcwCHhJKTUQKKYZwwWtESsuPgWIRwt1oIjc4VmrWh6l+/03W9//9iIEZ5sA76JERHzQIvCmUup9T9vjZkYCk0UkFR36uxpdYr4QNgElwC9FxEdExgCTrPzPilV6Wwn8RURCRMRLRC4VEdcQzxLgFmCmdVxNMLrEmy8i4cATDbziJJCmlKqu6S1FC8PFzDXAYaVUjlKqEt3OMsLDNrUUWSLSBcDaZzdXxu1FCDYDPUUkXkR80XHZDz1sk1sRHYv4J7BHKTXf0/a4G6XUr5VSMUqpOPTv9yv0LI0f1RtHsOwc8qxAO/6JVl4vAncppfaeg2l3Ab7AbrTjXgp0cXnHJnRJvivwmctzC9BtALnARmBFA3mfAo65NF6Ptd5zMXMUGC4idutvfCwXeQO5Cx8Cd1vHdwMfNFfG7WZksYhch/7nsgELlVJPn+WRNo2IjAK+Br4DqmPcv7Hmf7qosUruv1BK3eBpW9yNiAxAN477ontAzVZKnfSsVe5FRH6PrkVVAdup7YV10SAibwFj0LXaLHSNcDk6lNgN3VZ1s1KqfoPy+b2vvQiBwWAwGBqmvYSGDAaDwdAIRggMBoOhnWOEwGAwGNo5bW5AWWRkpIqLi/O0GQaDwdCm2Lp1a65SqmND99qcEMTFxbFli9uWNTYYDIaLEhE50tg9ExoyGAyGdk6bqxEYDIZ2TnkRZO4E/1CIvAxsPp62qM1jhMBgMLRelIL8I3Dsf9a2CbJ2QfW8ezY/6NwHovpCVD/o0h86J4JvoGftbmMYITAYDHWorKwkLS2NsrKysydubpQCRwU4yqGqAqrKLacfChHjodMk8PYDmy8oJzgqrfQV4HBC2klIWwdePuDtq/c2X11r8LK1/Pd4AH9/f2JiYvDxaXpNyQiBwWCoQ1paGsHBwcTFxeEyfbZ7qKqAymKosLbKUvSkmr5gC9Ile99A8AkEnwBozB6ltChUlug8KkuhqlQLBACVukXUJwB87NY+QIuEu7+xBVFKkZeXR1paGvHx8U1+zgiBwWCoQ1lZmXtEQDm1g65wcfzOSuumgK8dgjpqp+8beG6xfxFdA/D2hYAOtdcdVVoQXAWi3GU2drHVikK1SHj7gbRgPxqlwFkFTkftXlXVu2YdB3XSbSONICJERESQk5NzTiYYITAYDKfRLCLgqLRK+dWOv4SaKfS9fGpL+77VpX03OF+bN9iCwc9lrSKnA6rKLGGwBKI4j9q5GaUBcfA/e2hJKS12rs5bORp26K7HNesMNYTo93p5630T5oY7n9+dEQKDwXDhKKVL3q6l/ZqwjOVYAyNrwzzevp6z1ctWK0DVKOUiDpZAlOZDSV5tGpufJQo+dUvvrvszrRUjXrUO3ctb52ezgXjXvV6z99bPtEDoygiBwWA4N5TSjbhVZdphVhTrffWKnl7e2skGRlqxfTt4Nb20n5+fz5IlS7j//vvP2bTrrruOJUuW0KFDh7MndkVcagHV1LQ7lEJVCVSU6tpNWWVdp23zA9+GHHo9596S4aZzxAiBwWBomOoePFVlUFlmxdrL9Llrydc7AALCa0vZF9gAm5+fz4svvtigEFRVVeHt3bjb+vTTZlxuw2p3qMIL74DauPzZbDjXdK2BtmGlwWBwH0pBcQ5k74bsPeDTD3K+h6oyfv/fk+zOcWnQ9fKywhVeuqFVBChDL77WNPp0DeGJSYmN3n/00Uc5ePAgAwYMYNy4cVx//fU8/vjjhIWFsXfvXvbt28fUqVM5duwYZWVlPPTQQ8yZMweonYKmqKiIiRMnMmrUKNavX090dDQffPABAQEBdd6Vk5PDfffdx9GjRwFYsGABI0eOZO7cuRw8eJBDhw7RrVs3evXqVef8j3/8I//3f/9Hbm4uHTt2ZNGiRXTr1o1Zs2bh7+/P9u3bGTlyJPPnt43FAY0QGAztidJ8yNlb6/Sz9+hj11j4hPe0o7eHg28V+JRaYY2W6Wb5zDPPkJKSwo4dOwBYs2YN27ZtIyUlpaZL5MKFCwkPD6e0tJQhQ4Ywffp0IiIi6uSzf/9+3nrrLV599VVuvvlm3nvvPe64o+469w899BA//elPGTVqFEePHmX8+PHs2aNXvty9ezfr1q0jICCAuXPn1jmfNGkSd999N3fffTcLFy7kwQcfZPny5YDufrt+/XpstrYzbsEIgcFwMVJRArnf1zr6aqd/Kr02jW8QdEqA3tdDpz76uFMfOJYHkT0BeOLGWA99QF2GDh1ap1/8c889x7JlevnpY8eOsX///tOEID4+ngEDBgAwePBgUlNTT8t31apV7N5du8zzqVOnKCoqAmDy5Ml1ahCu5xs2bOD9998H4M477+SXv/xlTboZM2a0KRGAdiQETqdCpJm6xRnaN45KOHGo1rnm7IHsvXDysC4523xdNp/akbDVm7dvvTSu1/z0MzZf6zmfM1zzrR09W5RZt4R/4jA1cXybH3TsBXGjoVPvWqcfGttILD+vgWueJTCwtofPmjVrWLVqFRs2bMButzNmzJgGR0H7+fnVHNtsNkpLS09L43Q62bhxI/7+/md8Z0PnTbG1rdBuhODDb4/z8n8PctPgGKYMiKZjsN/ZHzK0b5wO7VCrHX32bh1Wyd1fdyBUeLx2rpeN147VUal71dRMfVBx+rWKYj2q1lFvq7lWXtsLp6mIDSJ66Dl3+t1aW8IPi9P96dsIwcHBFBYWNnq/oKCAsLAw7HY7e/fuZePGjef9rmuvvZbnn3+eRx55BIAdO3bU1CLOxIgRI3j77be58847efPNNxk9evR529AacOtfh4hMAP4G2IDXlFLP1Lt/H/AA4ACKgDlKqd2nZdQMhAR44+9j46lP9vDHz/ZyVa+O3DQ4hqt7d8bXu/V26zpvTmXA4f9CeSH0ug5Coz1tUevF6dQTm7mW7nP2QM4+7ZCr6dBdO9ee11ql6t569kufgMbzviC7HJY4lFtz6pTXExXrWlW57qoZeZmuMbRxIiIiGDlyJElJSUycOJHrr7++zv0JEybw8ssvk5CQQK9evRg+fPh5v+u5557jgQceoF+/flRVVXHFFVfw8ssvn/W5559/ntmzZ/Pss8/WNBa3ZUQ1YaTaeWUsYgP2AeOANGAzcJuroxeREKXUKet4MnC/UmrCmfJNTk5WF7IwzYHsQv6zNY1l29LJLiwnzO7DlAHR3DQ4hsSuIW03dFR2ClLXwaE1WgBy9ta93+1ySJoOfaboYertEaWg4Fjd0n32Hsjdp/vBVxMaCx17a0ffMcFy+L3AL8hztrcge/bsISEhwdNmGC6Ahn6HIrJVKZXcUHp31giGAgeUUocsI94GpgA1QlAtAhaBnHFYXvPQo1Mwv56YwCPX9uLrA7ks3ZrGkk1HWbw+ld5Rwdw0OIapA6OJDGrlJauqCkjbrB3/oTWQvlUPVfcOgO4jYMBMuGSMHsyzaxmkvAef/gI++6WOFSfdCAmTdc+Qiw2l4NRxl5COVdLP+R4qimrTBXfRDn/w7Fqn37EX+Id4znaDwQO4s0ZwEzBBKXWPdX4nMEwp9eN66R4Afgb4AlcrpfY3kNccYA5At27dBh850uiKa+dFfkkFH+3MYOnWNL49lo+3lzCmVycrdNSpdYSOnE5diq12/Ee+0aVY8YLowdrpx18JsUMbDw9k7YZd70PK+3DioB7xeMlVuqbQ+7ozTmbVqqmqgOPb4PDXkLoWjn8L5QW19wM76pBOdem+eh8Q5jmbWzGmRtD2OdcagceFwCX97cB4pdTdZ8r3QkNDZ2NfViHvbU3j/e3p5LiEjmYkx5DYtYUdZf6xWsd/+L960A/oWPAlY/TWfWTd2RabglKQ8W2tKBQc0z1Leo6DxGnQa2LrXtjDUQUZO+DwWkj9Go5urA3tdO4LsUNqe8Z0TIDAiDPnZ6iDEYK2T2sSgsuBuUqp8db5rwGUUn9sJL0XcFIpdUZv624hqKbK4eTr/Tp09MXuLCocThK6hFi9jrq6J3RUelKXaqud/4mD+npQ51rHH39l8zb8KgVpW3ToaNcy3Q3Rx657wCRNhx7jwOf0rnUtitMBmd9pp3/4aziyHiqsXiUdEyB+tA53xY26OENdLYwRgrZPaxICb3Rj8VggHd1YfLtSapdLmp7VoSARmQQ80Zih1bSUELiSX1LBR98e16GjtAK8vYSreuvQ0VW9LiB0VFmml96rdvwZO3SXQd8g7dQuGaO3jr1bZvEMpwOObtC1hN3L9WhT32A94ChpuralJWaNrA6D1Tj+dVBmhXoieminX+3822vDtxsxQtD2aTVCYL34OmABuvvoQqXU0yLyB2CLUupDEfkbcA1QiZ6s5MeuQtEQnhACV/ZlFbJ0axrvb0snt6ic8EBfplq9jvp0PUsjo9OpF92udvxHN+gJvLy8IWZIreOPHuz5BbkdVTrenvIe7PlIO2L/DtBnMiTeqJ1wc/VNV0o35KZ+rcM9R76pnfKgQ3eIv0JvcaMgpGvzvNPQKEYI2j6tSgjcgaeFoJoqh5O1+3NYujWNVbuzqXA46VMdOurXiQgKoDBD9+cvSNNO//BaKD2hM+jUxyXOP6LuwhmtjaoKOPiVblPY+4nueRPYUXdFTZoOscPPaZphlNIjc6tj/Ie/huJsfS8kpra0Hz8aOnRzzzcZGqUtCkFQUBBFRUUcP36cBx98kKVLl56WZsyYMcybN4/k5MaDDgsWLGDOnDnY7XbgAqa19jCtqfvoxYdSOo5fmIH3qQyuLsng6pgMyu3pZB9PpexkGiFf5NLhiwKQegIb3FU3wl4yRpdug6M88QXnh7cv9Jqgt8pS2P+FrilsfxM2v6a/LXGa7pIaPbjhMNbJVKtXj+X4C4/r60FRcMmVtY4/LP6iWkPW0LJ07dq1QRFoKgsWLOCOO+6oEYJmndb6LNSftrolp7s2QlBNRTEUZur+54WZujRfvZ2qPs6sO9LUws8eQWxwF4iLJ987mfWn7Hyd6cPBsiDK/DszuG8fRvZLYGD38NbRFfVC8AnQ4aE+k6G8CPat0KKw+VXY+IIuwSfeqEXvZKou9R/+Ggr0NL/YI3WIJ340xF2hJzczjr/18tmjuqG+OYnqCxOfafT2o48+SmxsLA888AAAc+fOJSgoiPvuu48pU6Zw8uRJKisreeqpp5gyZUqdZ1NTU7nhhhtISUmhtLSU2bNn8+2339K7d+86cw396Ec/YvPmzZSWlnLTTTfx+9//nueee47jx49z1VVXERkZyerVq2umtY6MjGT+/PksXLgQgHvuuYeHH36Y1NTUi2K66/YjBCdTIWOn5eSP13P6mXX7nVfjEwghXfTAo9hhuhQf0lXvg6v3UXX67XcARgPDHU7W7tOho5e2ZPHcpk3YfW0Miw9nZI9IRvWMpFfn4LY7khn0SNu+N+mtNF+HjXa9D+ufh28W6DT+HbTjH/Fja9KzBOP4DWfklltu4eGHH64RgnfffZfPP/8cf39/li1bRkhICLm5uQwfPpzJkyc3+j/00ksvYbfb2bNnDzt37mTQoEE1955++mnCw8NxOByMHTuWnTt38uCDDzJ//nxWr15NZGRknby2bt3KokWL2LRpE0ophg0bxpVXXklYWNhFMd11+xGCXcth1RP62MtbO/fgKD2S9JIxDTv5Cxhh6mPzYmxCZ8YmdKagtJKNh/L45kAu6w7ksvoT/QcQGeTHyB4RWhh6RNK1g5vmrGkJAjrAwJl6K87TDc3hl+h+/efSfmBoXZyh5O4uBg4cSHZ2NsePHycnJ4ewsDBiY2OprKzkN7/5DWvXrsXLy4v09HSysrKIimo4zLp27VoefPBBAPr160e/fv1q7r377ru88sorVFVVkZGRwe7du+vcr8+6deuYNm1azcyiN954I19//TWTJ0++KKa7bj9C0O9muPQq7eTtES3qnEIDfBifGMX4RP0Hm55fyjcHcmu2D3boePklHQMZ1SOSkT0iGX5JBKEBHu45dL4ERug2A4PhPJkxYwZLly4lMzOTW265BYA333yTnJwctm7dio+PD3FxcQ1OP302Dh8+zLx589i8eTNhYWHMmjXrvPKp5mKY7rr9FNVCukKX/hDU0eMl1OgOAdycHMvfbh3I5t9ew4qHR/PY9Ql0D7ezdGsaP/zXVgb+YSVTX/iGeZ9/z4aDeZRXOTxqs8HQktxyyy28/fbbLF26lBkzZgB6+ulOnTrh4+PD6tWrOdtUM1dccQVLliwBICUlhZ07dwK6NB4YGEhoaChZWVl89tlnNc80NgX26NGjWb58OSUlJRQXF7Ns2bJzmnq6errraqpXXzsb1dNdA26d7rr91AhaKSJC76gQekeFcM/oS6iocrLjWD7rDuSybn8OL/33IH9ffQB/Hy+GxkcwqkcEo3p0pHdUMF5eJtZuuDhJTEyksLCQ6OhounTpAsDMmTOZNGkSffv2JTk5md69e58xjx/96EfMnj2bhIQEEhISGDx4MAD9+/dn4MCB9O7dm9jYWEaOHFnzzJw5c5gwYQJdu3Zl9erVNdcHDRrErFmzGDp0KKAbiwcOHNhgGKghWvt012YcQSvnVFklmw6dqGlfOJCt44oRgb6M6BHJKKuNISbM7mFLDRcLbXEcgaEuZhzBRUaIvw/j+nRmXJ/OAGQWlNW0Law7kMtH3+r2hbgIe02j84hLIwm1t9H2BYPB0OIYIWhjRIX6M31wDNMHx6CU4kB2EessYVi+PZ03Nx1FBPpFhzKyRySje3ZkSFwY3rb20xxkMBjODSMEbRgRoWfnYHp2Dmb2yHgqHU6+tdoXvjmQyytrD/HimoOEB/oyLqEzE5KiGNEjAj/v5ulyZrh4UUq17TEu7ZjzCfcbIbiI8LF5kRwXTnJcOA9fcxlF5VV8vS+HFbsy+fS7DN7ZcoxgP2+uTujEhMQoruzVEbuv+RMw1MXf35+8vDwiIiKMGLQxlFLk5eU12E31TJjG4nZCeZWD9QfzWPFdJl/syeJEcQV+3l5ceVlHJvaN4urendvuuAVDs1JZWUlaWtoF9a03eA5/f39iYmLw8an7/3xBs49aC8YMV0qtbzZLLwAjBBdOlcPJ5tSTfL4rkxUpmWSeKsPbSxjRI5IJiVGM69OZjsGtfM1mg8FwTlzwNNQisl0pNbDZLTsPjBA0L06n4tu0fFZYonAkrwQRGBIXzoTEKMYnRRHdlqe+MBgMQPMIwTxgA/C+8nAsyQiB+1BKsTezkBUpmXy+K5O9mXqEZb+YUCYkRTEhMYpLOgZ52EqDwXA+NIcQFAKBzp6PVQAAEZxJREFUgAMoBQRQSqnzn5XtPDFC0HIcyini811ZrNiVybfH8gG4rHNQTU2hT5cQ05hoMLQRzAplhgvmeH4pK3dl8llKJptTT+BU0C3czoQkPZnewNgOZsoLg6EV0yxCICKTgSus0zVKqY+byb5zwgiB58ktKmfV7iw+S8lk/cFcKh2KziF+jE/U4aOh8eFmAJvB0MpojtDQM8AQ4E3r0m3oBeh/3WxWNhEjBK2LgtJKVu/NZkVKJmv2ZVNW6STM7sM1CZ2ZPKArIy6NxGZqCgaDx2kOIdgJDFBKOa1zG7BdKdX4Sg5uwghB66Wkooq1+3JYkZLJl3uyKSyvolOwH1MGdGXqwGjTpmAweJDmmnSuA3DCOg69YKsMFx12X28mJHVhQlIXyiodfLU3m/e3pbPom1Re/fowvToHM3VgNFMGdG3bq7EZDBcZTa0R3Ar8CViN7jF0BfCoUuod95p3OqZG0PY4UVzBJ99lsGxbGtuO5iMCw+MjmDYwmgl9owjxNyOaDQZ30xwji28Cvka3EwD8TymV2axWNhEjBG2bI3nFLN9+nGXb00jNK8HP24tr+nRm2oBoruzVER/TyGwwuIXmaCPY0lgGLY0RgosDpRQ7juWzfPv/b+/eg+MqzzuOfx/dL5a0sm6WVhI2tiRjfJGYFOxCbW6ZOA1g0zYF0mTSNhlmMiWllzS3/tE2Q1om0+lASqYzlNIyEyZpQ2JsSIAQoIik4Dix5LslGdvIWl2si1d3aSXt0z/Okbwo8n1XR9J5PjOa3X33oucMRr993/ec9w3x0sEO+oYjLM9O456NpdxfF6S2ImDzCcbEUbzOGuoB/hsYnm5X1b4LvilBLAiWnompKPXN3exqCPH60S7GJ6OsKsxmZ22QnXVlXFcQv026jfGreATBqTmaVVWvv8T7tgNPAsnAM6r6+Kzn/wr4PDAJdAN/qqoX3ZHagmBpGxib4NXDnezaH+K9U72owk2VAe6/qZx7NpSSn53mdYnGLErxmCP45JVODLunmDYDHwXagH3AQ6p6NOY1dwB7VXVERL4A3K6qD1zscy0I/KM9PMqeA+3s2h+iqWuQ1GRhW3Uxv3dTkDvXFpORahvsGHO5PJkjEJEtwN+r6sfcx18DUNV/usDr64CnVPXWi32uBYH/qCrHOgZ5sTHE7sYQXQPj5GSk8IkNpeysC3LzyuW2vIUxlxCP6wh+JiJf4srmCILAmZjHbcAtF3n954BX5npCRB4GHgaorKy8zJLNUiEirCvLZV1ZLl/ZvpZ33+9lV0OIlw608/19ZwgGMtlRW8b9dUGqSnK8LteYRSdhcwQi8gfAdlX9vPv4M8AtqvrIHK/9NPAIsE1Vxy9Wi/UIzLSRyCSvH+3ixYYQ9S09TEWV9cFcdtYGuXdTGSW5V7ZdnzFL2TX3CFR11VX83hBQEfO43G2bXdzdwN9yGSFgTKystBR21AbZURuke3Cclw+2s6shxGM/PsY3f3KMLdcXsLM2yMfWr7BtOI25iIv2CETky6r6Lff+J1X1BzHP/aOqfv0i703BmSy+CycA9gGfUtUjMa+pA17A6Tm0XE7B1iMwl3Kye4jdje3sbgxxuneEtJQk7qwpZkdtGXfYJLPxqaueLBaR/ap60+z7cz2+wPt/F3gC5/TRZ1X1myLyDZyVS/eIyM+ADUCH+5ZWVb3vYp9pQWAul6pysK2f3Y3tvHSwne7BcXLSU9i+fgU7aoNsWV1gK6Ma37iWIJjZq3j2vsVe7WNsQWCuxlRUeff9Xl5sDPHq4U6Gxicpyknn3o1l7KgtY2N5nl3JbJa0a5kj0Avcn+uxMQtWcpJwW1Uht1UV8tjO9bx1/CwvNob47nsf8OwvTrGqMJv7NjmhYPsyG7+5VI9gCud0UQEygZHpp4AMVZ33GTjrEZh46h+d4NXDHexubOfdk86VzBvL87hvUxn3bSqj2M48MkuE7VlszGXo7B/j5YPt7G5s51ConySBLasL2FEbZPt6Wy7bLG4WBMZcoRNnh9hzwDnz6IOYM4921pVxe42deWQWHwsCY66SqnKgrZ/djSFeOtBBz5CzvMXH3TOPNl9vZx6ZxcGCwJg4mJyK8u7JXl5saOe1I86ZR8U56dzrTjJvCNqZR2bhsiAwJs7GJqZ449hZdjeG+N+mbiJTzh4Kd9QUs7W6kM3XF9jwkVlQLAiMSaD+kQleOdzBjw91sPdUH5HJKGkpSdyyajlbq4rYVlNEVfEy6y0YT1kQGDNPRiNT7D3VS31zD/Ut3Zw4OwTAitwMtlYXsrW6iNvWFBLIsg12zPyyIDDGI6HwKO80d1Pf0s3PW3oYGJskSWBjeYCt1UVsqy5kU3mAlOQkr0s1S5wFgTELwORUlANt/bzd3E19czcH28JEFXIzUrh1jdNb2FpdRDCQ6XWpZgmyIDBmAQqPRPj5iR7qm7upb+6hc2AMgNVF2TOhsHlVAZlpNulsrp0FgTELnKrScnaI+uZu3m7u5pen+hifNem8tbqI6hKbdDZXx4LAmEVmbGKKvaf63N5CNy0xk86/U3V+0jk/2yadzeWJx57Fxph5lJGazLbqIrZVFwHQHh7lnRZnCOm1I5384NdtiDvpvK2qkM2rC9hUHiA73f6XNlfOegTGLDLTk8717tlIB844k85JAtUlOdRV5lNXGaCuIsDqomUk2RIYBhsaMmZJ6x+ZYP+ZczS2hmk4E6ax9RwDY5MA5GSkUFvhhEJdZT61FQEbTvIpGxoyZgnLy0rljppi7qgpBiAaVU72DNPQes4NhjBPvXWCqPudb2VBVkyvIZ+1pTmk2nUMvmY9AmN8YHh8kkOhfhpawzMB0T04DkB6ShIbgnlOMLgBUZpn1zIsNTY0ZIz5EFWlvX/MCQU3HA63DxCZjALO2Ul1lQFnWKkynw3BPLueYZGzoSFjzIeICMFAJsFAJvdsLAMgMhnlWMfATI+hoTXMK4c7AWfP5xtKc6iryJ8JiFWF2XZNwxJhPQJjzAX1DI3T2Bqm8UyYhjPnOHCmn6FxZyI6kJXKxvIAN6zIoWZFDtUlOawpXmbLby9Q1iMwxlyVwmXp3L2uhLvXlQAwFVVOnB2iofUcjWfCHGjr5733e4lMOUNKSQIrC7NZ6wbD2hU51KzIpXJ5lu3ktoBZEBhjLltyklDj9gAevLkSgImpKB/0DnO8c5DmzkGOdw5ypH2AVw53Mj3gkJGaRFXx+XCoXuHcFuek2/DSAmBBYIy5JqnJSawpzmFNcQ5sPN8+EpmkpWuIpq5BmjoHae4apL6lmx/ub5t5TSArleqSHGpKcmYCprokh7zMVA+OxL8sCIwxCZGVlsKmigCbKgIfau8bjtDUOUhT5wBNXUM0dQ6wqyE0M/cAUJaXQbUbDNMhsbrI5h8SJaFBICLbgSeBZOAZVX181vNbgSdwvkc8qKovJLIeY4z3lmensWV1AVtWF8y0qSqh8CjNXc7QUpP784sTPUxMOeNLyUnCyoIsNxxyua4gi9K8DMoCmazIy7CL4q5BwoJARJKB7wAfBdqAfSKyR1WPxrysFfhj4EuJqsMYs/CJCOX5WZTnZ3Hn2pKZ9ompKKd73PmHrrnnH5z3Q9GydEoDmQQDGZTmZc6ERFkgk7K8DAqXpdu6SxeQyB7BzcAJVT0JICLfB3YAM0Ggqqfd56IJrMMYs0ilJidRVZJDVUnOh9pHIpO0h0dpD4/R0T9KKDxGR3iUjv4xjncO8ubxs4xNRGd9lrAizwmJsrwMSmNCojTPuaYiNzPFl5PXiQyCIHAm5nEbcMvVfJCIPAw8DFBZWXntlRljFrWstJTzE9RzUFXCIxO094/SER6jvf98aHSEx9h3+hxdAx1MRnXW5yaf70nkZVIayDh/67YtxSusF8Vksao+DTwNzgVlHpdjjFngRIT87DTys9O4sSxvztdMRZWeofEP9SzO345yvHNwZj2mWLkZKRQsS6cgO43l2WkULHNul2efb4ttT09Z+MGRyCAIARUxj8vdNmOM8VxyklCSm0FJbgZ1FxhoiExG6RoYc8LCDYqzA2P0DkfoHYrwQe8I+1vDnBuJMBWd+zvqsvSUmWA4HxQxoRHTXpCd7kmPI5FBsA+oEpFVOAHwIPCpBP4+Y4yJq7SUJCqWZ1GxPOuir4tGlYGxCXqHI/S5IdE3HKFveJyemfsRQuExDoX66RuOzJwNNVtmavKs4Eif6V1sqy7ihtLcuB9nwoJAVSdF5BHgNZzTR59V1SMi8g3gV6q6R0R+C9gF5AP3isg/qOqNiarJGGMSISlJCGSlEchKY3XRpV+vqgyOT9I3FJkJj9mh0TscoXtonKbOQXqHI4xPRsnLTE1IENiic8YYs8CpKiORKZJErnroyBadM8aYRUxEyE5P3J9ruxTPGGN8zoLAGGN8btHNEYhIN/DBVb69EOiJYzmLgR2zP9gx+8O1HPN1qjrnVPaiC4JrISK/utBkyVJlx+wPdsz+kKhjtqEhY4zxOQsCY4zxOb8FwdNeF+ABO2Z/sGP2h4Qcs6/mCIwxxvwmv/UIjDHGzGJBYIwxPuebIBCR7SLSJCInROSrXteTaCJSISJvichRETkiIo96XdN8EJFkEWkQkZe9rmU+iEhARF4QkeMickxEtnhdU6KJyF+6/6YPi8j3RCTD65riTUSeFZGzInI4pm25iLwuIi3ubX68fp8vgiBm/+SPA+uAh0RknbdVJdwk8Nequg7YDPyZD44Z4FHgmNdFzKMngVdVdS2wiSV+7CISBP4c+IiqrsdZ2fhBb6tKiP8Cts9q+yrwhqpWAW+4j+PCF0FAzP7JqhoBpvdPXrJUtUNV97v3B3H+QAS9rSqxRKQc+ATwjNe1zAcRyQO2Av8BoKoRVQ17W9W8SAEyRSQFyALaPa4n7lS1Huib1bwDeM69/xywM16/zy9BMNf+yUv6j2IsEVkJ1AF7va0k4Z4AvgxEL/XCJWIV0A38pzsc9oyIZHtdVCKpagj4Z6AV6AD6VfWn3lY1b0pUtcO93wmUxOuD/RIEviUiy4AfAn+hqgNe15MoInIPcFZVf+11LfMoBbgJ+DdVrQOGieNwwULkjovvwAnBMiBbRD7tbVXzT53z/uN27r9fgsCX+yeLSCpOCDyvqj/yup4EuxW4T0RO4wz93Ski3/W2pIRrA9pUdbqn9wJOMCxldwOnVLVbVSeAHwG/7XFN86VLREoB3Nuz8fpgvwTBzP7JIpKGM7m0x+OaEkpEBGfs+Jiq/ovX9SSaqn5NVctVdSXOf983VXVJf1NU1U7gjIjUuE13AUc9LGk+tAKbRSTL/Td+F0t8gjzGHuCz7v3PArvj9cG+2KHsQvsne1xWot0KfAY4JCKNbtvXVfUnHtZk4u+LwPPuF5yTwJ94XE9CqepeEXkB2I9zZlwDS3CpCRH5HnA7UCgibcDfAY8D/yMin8NZiv8P4/b7bIkJY4zxN78MDRljjLkACwJjjPE5CwJjjPE5CwJjjPE5CwJjjPE5CwJjZhGRKRFpjPmJ29W6IrIydkVJYxYCX1xHYMwVGlXVWq+LMGa+WI/AmMskIqdF5FsickhEfikia9z2lSLypogcFJE3RKTSbS8RkV0icsD9mV4KIVlE/t1dU/+nIpLp2UEZgwWBMXPJnDU09EDMc/2qugF4Cme1U4B/BZ5T1Y3A88C33fZvA2+r6iacNYCmr2avAr6jqjcCYeD3E3w8xlyUXVlszCwiMqSqy+ZoPw3cqaon3QX9OlW1QER6gFJVnXDbO1S1UES6gXJVHY/5jJXA6+7mIojIV4BUVX0s8UdmzNysR2DMldEL3L8S4zH3p7C5OuMxCwJjrswDMbfvuvf/j/PbJf4R8I57/w3gCzCzl3LefBVpzJWwbyLG/KbMmBVbwdkTePoU0nwROYjzrf4ht+2LOLuE/Q3OjmHTK4A+CjztrhY5hRMKHRizwNgcgTGXyZ0j+Iiq9nhdizHxZENDxhjjc9YjMMYYn7MegTHG+JwFgTHG+JwFgTHG+JwFgTHG+JwFgTHG+Nz/Ay3z19reChRIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OafoynVsNM2C",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "outputId": "7fe7f3f5-cd64-4f00-db0b-10bc8722dc1c"
   },
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluating model on test data...\")\n",
    "results = model.evaluate(x_test, y_test_one_hot, batch_size=batch_size)\n",
    "print(\"Test loss:\", results[0])\n",
    "print(\"Test acc:\", results[1])\n",
    "\n",
    "y_test_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification reprot:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=8))"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Evaluating model on test data...\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2793 - accuracy: 0.5025\n",
      "Test loss: 0.2792723476886749\n",
      "Test acc: 0.5024999976158142\n",
      "Confusion matrix:\n",
      "[[58  5  4 11  5  3  9  5]\n",
      " [ 6 39 13  9 10  5  9  9]\n",
      " [ 2 18 53  0  6 10  7  4]\n",
      " [15  3  5 67  2  3  3  2]\n",
      " [ 8 18 25  0 41  0  8  0]\n",
      " [13  4 16  5  4 48  7  3]\n",
      " [17  7 17  8  5  8 28 10]\n",
      " [ 5  9  7  1  0  3  7 68]]\n",
      "Classification reprot:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.46774194 0.58000000 0.51785714       100\n",
      "           1  0.37864078 0.39000000 0.38423645       100\n",
      "           2  0.37857143 0.53000000 0.44166667       100\n",
      "           3  0.66336634 0.67000000 0.66666667       100\n",
      "           4  0.56164384 0.41000000 0.47398844       100\n",
      "           5  0.60000000 0.48000000 0.53333333       100\n",
      "           6  0.35897436 0.28000000 0.31460674       100\n",
      "           7  0.67326733 0.68000000 0.67661692       100\n",
      "\n",
      "    accuracy                      0.50250000       800\n",
      "   macro avg  0.51027575 0.50250000 0.50112154       800\n",
      "weighted avg  0.51027575 0.50250000 0.50112154       800\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GuvMmO6k3UuT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Big model + RNN\n",
    "\n",
    "def build_model_CNN_RNN_BIG(input_shape):\n",
    "    X_input = layers.Input(input_shape)\n",
    "\n",
    "    X = layers.Conv2D(32, (5, 5), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X1 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X1 = layers.BatchNormalization()(X1)\n",
    "\n",
    "    b1 = layers.MaxPool2D((2, 2))(X) \n",
    "    b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "    b1 = layers.BatchNormalization()(b1)\n",
    "    b1 = layers.Activation('relu')(b1)\n",
    "    b1 = layers.Conv2D(128, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "    b1 = layers.BatchNormalization()(b1)\n",
    "\n",
    "    X = layers.Add()([X1, b1])\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X1 = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X1 = layers.BatchNormalization()(X1)\n",
    "\n",
    "    b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "    b1 = layers.BatchNormalization()(b1)\n",
    "    b1 = layers.Activation('relu')(b1)\n",
    "    b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
    "    b1 = layers.BatchNormalization()(b1)\n",
    "\n",
    "    X = layers.Add()([X1, b1])\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
    "    X2 = layers.BatchNormalization()(X2)\n",
    "\n",
    "    b2 = layers.MaxPool2D((2, 2))(X) \n",
    "    b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
    "    b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation('relu')(b2)\n",
    "    b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
    "    b2 = layers.BatchNormalization()(b2)\n",
    "\n",
    "\n",
    "    X = layers.Add()([X2, b2])\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X2 = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
    "    X2 = layers.BatchNormalization()(X2)\n",
    "\n",
    "    b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
    "    b2 = layers.BatchNormalization()(b2)\n",
    "    b2 = layers.Activation('relu')(b2)\n",
    "    b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
    "    b2 = layers.BatchNormalization()(b2)\n",
    "\n",
    "    X = layers.Add()([X2, b2])\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X3 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
    "    X3 = layers.BatchNormalization()(X3)\n",
    "\n",
    "    b3 = layers.MaxPool2D((2, 2))(X) \n",
    "    b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
    "    b3 = layers.BatchNormalization()(b3)\n",
    "    b3 = layers.Activation('relu')(b3)\n",
    "    b3 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
    "    b3 = layers.BatchNormalization()(b3)\n",
    "\n",
    "\n",
    "    X = layers.Add()([X3, b3])\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X3 = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
    "    X3 = layers.BatchNormalization()(X3)\n",
    "\n",
    "    b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
    "    b3 = layers.BatchNormalization()(b3)\n",
    "    b3 = layers.Activation('relu')(b3)\n",
    "    b3 = layers.Conv2D(128, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
    "    b3 = layers.BatchNormalization()(b3)\n",
    "\n",
    "    X = layers.Add()([X3, b3])\n",
    "    X = layers.Activation('relu')(X)\n",
    "\n",
    "    X = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    X = layers.MaxPool2D((2, 2))(X)\n",
    "\n",
    "    X = layers.Flatten()(X)\n",
    "\n",
    "    ##### Recurrent Block #####\n",
    "\n",
    "    # Pooling layer\n",
    "    R = MaxPooling2D((1, 2), strides=(1, 2), name='pool_lstm')(X_input)\n",
    "\n",
    "    # Embedding layer\n",
    "    squeezed = layers.Lambda(lambda x: tf.keras.backend.squeeze(x, axis=-1))(R)\n",
    "    #flatten2 = K.squeeze(pool_lstm1, axis = -1)\n",
    "    #dense1 = Dense(dense_size1)(flatten)\n",
    "    \n",
    "    # Bidirectional GRU\n",
    "    lstm = layers.Bidirectional(layers.GRU(64))(squeezed)\n",
    "    \n",
    "\n",
    "    ##### Concatenate blocks #####\n",
    "    # Concat Output\n",
    "    concat = layers.concatenate([X, lstm], axis=-1, name='concat') #TODO: add?\n",
    "    \n",
    "    ## Softmax Output\n",
    "    output = Dense(8, activation='softmax', name='preds')(concat)\n",
    "    \n",
    "    model_output = output\n",
    "    model = tf.keras.models.Model(X_input, model_output)\n",
    "    \n",
    "    opt = Adam(lr=0.001)\n",
    "    #opt = tf.keras.optimizers.RMSprop(lr=0.0005)  # Optimizer\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TVs3fzY33WGe",
    "colab_type": "code",
    "outputId": "4f11a137-0eb1-4525-cbb4-0b225bdf2f99",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "model = build_model_CNN_RNN_BIG((128, 128, 1))\n",
    "checkpoint_callback = ModelCheckpoint(\"/content/drive/My Drive/Models/weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', verbose=1,\n",
    "                                          save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1,\n",
    "                               patience=20,\n",
    "                               mode='max',\n",
    "                               restore_best_weights=True)\n",
    "callbacks_list = [checkpoint_callback, early_stopping]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=50,\n",
    "                        validation_data=(x_val, y_val), verbose=1, callbacks=callbacks_list)\n"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 32)   832         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 32)   0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 16)   528         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 128)  2176        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 128)  36992       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2064        batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 128)  0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 256)  295168      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 256)  4352        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 256)  0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 32)   8224        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 512)  16896       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 512)  1180160     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 512)  2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 512)  2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 32)   16416       batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 512)  0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 512)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 512)  2359808     activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 512)  16896       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 512)  2048        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 512)  2048        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 512)  0           batch_normalization_30[0][0]     \n",
      "                                                                 batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 512)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 512)    0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 8, 64)     32832       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 64)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 8, 8, 512)    33280       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 512)    2359808     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 8, 8, 512)    2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 8, 8, 512)    2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 8, 8, 64)     32832       batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 512)    0           batch_normalization_33[0][0]     \n",
      "                                                                 batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 512)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 8, 8, 128)    589952      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 8, 128)    8320        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 8, 8, 128)    512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 128)    0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 128)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 64)     73792       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 64)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pool_lstm (MaxPooling2D)        (None, 128, 64, 1)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 64)     0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 64)      0           pool_lstm[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 128)          49920       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 1152)         0           flatten_1[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "preds (Dense)                   (None, 8)            9224        concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,148,136\n",
      "Trainable params: 7,139,304\n",
      "Non-trainable params: 8,832\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 1.6566 - accuracy: 0.4017\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.44625, saving model to /content/drive/My Drive/Models/weights.01-0.45.hdf5\n",
      "675/675 [==============================] - 40s 60ms/step - loss: 1.6566 - accuracy: 0.4017 - val_loss: 1.5910 - val_accuracy: 0.4462\n",
      "Epoch 2/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 1.4563 - accuracy: 0.4812\n",
      "Epoch 00002: val_accuracy did not improve from 0.44625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 1.4562 - accuracy: 0.4813 - val_loss: 1.8534 - val_accuracy: 0.3950\n",
      "Epoch 3/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 1.3520 - accuracy: 0.5207\n",
      "Epoch 00003: val_accuracy improved from 0.44625 to 0.51750, saving model to /content/drive/My Drive/Models/weights.03-0.52.hdf5\n",
      "675/675 [==============================] - 41s 60ms/step - loss: 1.3523 - accuracy: 0.5206 - val_loss: 1.4271 - val_accuracy: 0.5175\n",
      "Epoch 4/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 1.2520 - accuracy: 0.5608\n",
      "Epoch 00004: val_accuracy did not improve from 0.51750\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 1.2520 - accuracy: 0.5608 - val_loss: 1.7635 - val_accuracy: 0.3963\n",
      "Epoch 5/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 1.1620 - accuracy: 0.5963\n",
      "Epoch 00005: val_accuracy improved from 0.51750 to 0.55625, saving model to /content/drive/My Drive/Models/weights.05-0.56.hdf5\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 1.1621 - accuracy: 0.5963 - val_loss: 1.3828 - val_accuracy: 0.5562\n",
      "Epoch 6/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 1.0526 - accuracy: 0.6308\n",
      "Epoch 00006: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 1.0527 - accuracy: 0.6308 - val_loss: 1.7914 - val_accuracy: 0.4437\n",
      "Epoch 7/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.9185 - accuracy: 0.6770\n",
      "Epoch 00007: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.9187 - accuracy: 0.6769 - val_loss: 1.5601 - val_accuracy: 0.5312\n",
      "Epoch 8/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.7361 - accuracy: 0.7403\n",
      "Epoch 00008: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.7360 - accuracy: 0.7403 - val_loss: 1.9145 - val_accuracy: 0.4450\n",
      "Epoch 9/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.5170 - accuracy: 0.8214\n",
      "Epoch 00009: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.5169 - accuracy: 0.8214 - val_loss: 1.9785 - val_accuracy: 0.4950\n",
      "Epoch 10/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.3349 - accuracy: 0.8851\n",
      "Epoch 00010: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.3350 - accuracy: 0.8851 - val_loss: 2.6128 - val_accuracy: 0.4288\n",
      "Epoch 11/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.9345\n",
      "Epoch 00011: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.2039 - accuracy: 0.9345 - val_loss: 2.1798 - val_accuracy: 0.4988\n",
      "Epoch 12/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 0.9514\n",
      "Epoch 00012: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.1441 - accuracy: 0.9514 - val_loss: 2.9205 - val_accuracy: 0.3925\n",
      "Epoch 13/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1375 - accuracy: 0.9529\n",
      "Epoch 00013: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.1375 - accuracy: 0.9530 - val_loss: 2.7203 - val_accuracy: 0.4737\n",
      "Epoch 14/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1293 - accuracy: 0.9560\n",
      "Epoch 00014: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.1293 - accuracy: 0.9560 - val_loss: 2.9457 - val_accuracy: 0.4850\n",
      "Epoch 15/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9686\n",
      "Epoch 00015: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.0963 - accuracy: 0.9686 - val_loss: 2.7496 - val_accuracy: 0.5088\n",
      "Epoch 16/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1052 - accuracy: 0.9642\n",
      "Epoch 00016: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.1052 - accuracy: 0.9642 - val_loss: 2.8199 - val_accuracy: 0.4750\n",
      "Epoch 17/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9667\n",
      "Epoch 00017: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 57ms/step - loss: 0.0967 - accuracy: 0.9667 - val_loss: 3.1514 - val_accuracy: 0.4875\n",
      "Epoch 18/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.1085 - accuracy: 0.9634\n",
      "Epoch 00018: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.1086 - accuracy: 0.9633 - val_loss: 3.0106 - val_accuracy: 0.5113\n",
      "Epoch 19/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9745\n",
      "Epoch 00019: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.0748 - accuracy: 0.9745 - val_loss: 2.9855 - val_accuracy: 0.5238\n",
      "Epoch 20/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9732\n",
      "Epoch 00020: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.0827 - accuracy: 0.9730 - val_loss: 3.4787 - val_accuracy: 0.4500\n",
      "Epoch 21/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0846 - accuracy: 0.9717\n",
      "Epoch 00021: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.0847 - accuracy: 0.9717 - val_loss: 3.1761 - val_accuracy: 0.5050\n",
      "Epoch 22/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9770\n",
      "Epoch 00022: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.0698 - accuracy: 0.9770 - val_loss: 3.6292 - val_accuracy: 0.4725\n",
      "Epoch 23/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9756\n",
      "Epoch 00023: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.0742 - accuracy: 0.9756 - val_loss: 3.5738 - val_accuracy: 0.4888\n",
      "Epoch 24/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9790\n",
      "Epoch 00024: val_accuracy did not improve from 0.55625\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.0650 - accuracy: 0.9790 - val_loss: 3.3608 - val_accuracy: 0.5100\n",
      "Epoch 25/50\n",
      "674/675 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9741\n",
      "Epoch 00025: val_accuracy did not improve from 0.55625\n",
      "Restoring model weights from the end of the best epoch.\n",
      "675/675 [==============================] - 39s 58ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 3.9118 - val_accuracy: 0.4800\n",
      "Epoch 00025: early stopping\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kLSMZDXyexhs",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "outputId": "5337a9b7-2615-4317-b0fb-48a2db1b1a6c"
   },
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluating model on test data...\")\n",
    "results = model.evaluate(x_test, y_test_one_hot)\n",
    "print(\"Test loss:\", results[0])\n",
    "print(\"Test acc:\", results[1])\n",
    "\n",
    "y_test_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification reprot:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=8))"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Evaluating model on test data...\n",
      "25/25 [==============================] - 0s 20ms/step - loss: 1.3643 - accuracy: 0.5250\n",
      "Test loss: 1.3643012046813965\n",
      "Test acc: 0.5249999761581421\n",
      "Confusion matrix:\n",
      "[[68  8  7  4  8  4  1  0]\n",
      " [12 45  9  1 17 10  2  4]\n",
      " [ 0 17 65  0  3 11  3  1]\n",
      " [13  8  1 71  0  6  1  0]\n",
      " [ 8 24 26  1 37  2  0  2]\n",
      " [ 7  2 14  5  2 63  6  1]\n",
      " [24  7 17  7  3 20 17  5]\n",
      " [11 13  7  1  3  7  4 54]]\n",
      "Classification reprot:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.47552448 0.68000000 0.55967078       100\n",
      "           1  0.36290323 0.45000000 0.40178571       100\n",
      "           2  0.44520548 0.65000000 0.52845528       100\n",
      "           3  0.78888889 0.71000000 0.74736842       100\n",
      "           4  0.50684932 0.37000000 0.42774566       100\n",
      "           5  0.51219512 0.63000000 0.56502242       100\n",
      "           6  0.50000000 0.17000000 0.25373134       100\n",
      "           7  0.80597015 0.54000000 0.64670659       100\n",
      "\n",
      "    accuracy                      0.52500000       800\n",
      "   macro avg  0.54969208 0.52500000 0.51631078       800\n",
      "weighted avg  0.54969208 0.52500000 0.51631078       800\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a5heBw8i0SBa",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def build_model_CRNN(model_input):\n",
    "    X_input = layers.Input(model_input)\n",
    "    \n",
    "    ##### Convolutional blocks #####\n",
    "    # First convolutional block\n",
    "    X = Conv2D(68, (3, 3), strides=(1, 1), padding='same', name='conv_1')(X_input)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(1, 1))(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    # Second convolutional block\n",
    "    X = Conv2D(137, (3, 3), strides=(1, 1), padding='same', name='conv_2')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(1, 1))(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    # Third convolutional block\n",
    "    X = Conv2D(137, (3, 3), strides=(1, 1), padding='same', name='conv_3')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    X = MaxPooling2D((4, 4), strides=(1, 1))(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    # Fourth convolutional block\n",
    "    X = Conv2D(137, (3, 3), strides=(1, 1), padding='same', name='conv_4')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Activation('relu')(X)\n",
    "    X = MaxPooling2D((4, 4), strides=(1, 1))(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "\n",
    "    ##### Recurrent Block #####\n",
    "    \n",
    "    # GRU layer\n",
    "    lstm = layers.GRU(68)(X[:, :, :, 0])\n",
    "\n",
    "    ## Softmax Output\n",
    "    output = Dense(8, activation='softmax', name='preds')(lstm)\n",
    "    \n",
    "    model_output = output\n",
    "    model = tf.keras.models.Model(X_input, model_output)\n",
    "    \n",
    "    opt = Adam(lr=0.001)\n",
    "    #opt = tf.keras.optimizers.RMSprop(lr=0.0005)  # Optimizer\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zJTV1YYh3ixk",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "53d3c710-4217-4c01-f694-8fa858d29a5e"
   },
   "source": [
    "model = build_model_CRNN((128, 128, 1))\n",
    "checkpoint_callback = ModelCheckpoint(\"/content/drive/My Drive/Models/weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\", monitor='val_accuracy', verbose=1,\n",
    "                                          save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1,\n",
    "                               patience=10,\n",
    "                               mode='max',\n",
    "                               restore_best_weights=True)\n",
    "callbacks_list = [checkpoint_callback, early_stopping]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=32, epochs=30,\n",
    "                        validation_data=(x_val, y_val), verbose=1, callbacks=callbacks_list)\n"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 128, 128, 68)      680       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 68)      272       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 128, 68)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 68)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 127, 127, 68)      0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 127, 127, 137)     83981     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 127, 127, 137)     548       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 127, 127, 137)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 125, 125, 137)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125, 125, 137)     0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 125, 125, 137)     169058    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 125, 125, 137)     548       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 125, 125, 137)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 122, 122, 137)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 122, 122, 137)     0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 122, 122, 137)     169058    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 122, 122, 137)     548       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 122, 122, 137)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 119, 119, 137)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 119, 119, 137)     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 119, 119)]        0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 68)                38556     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 8)                 552       \n",
      "=================================================================\n",
      "Total params: 463,801\n",
      "Trainable params: 462,843\n",
      "Non-trainable params: 958\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.9646 - accuracy: 0.2280\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.23000, saving model to /content/drive/My Drive/Models/weights.01-0.23.hdf5\n",
      "675/675 [==============================] - 705s 1s/step - loss: 1.9646 - accuracy: 0.2280 - val_loss: 1.9970 - val_accuracy: 0.2300\n",
      "Epoch 2/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.8341 - accuracy: 0.3033\n",
      "Epoch 00002: val_accuracy improved from 0.23000 to 0.26125, saving model to /content/drive/My Drive/Models/weights.02-0.26.hdf5\n",
      "675/675 [==============================] - 703s 1s/step - loss: 1.8341 - accuracy: 0.3033 - val_loss: 1.8470 - val_accuracy: 0.2612\n",
      "Epoch 3/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.7432 - accuracy: 0.3397\n",
      "Epoch 00003: val_accuracy improved from 0.26125 to 0.30500, saving model to /content/drive/My Drive/Models/weights.03-0.31.hdf5\n",
      "675/675 [==============================] - 702s 1s/step - loss: 1.7432 - accuracy: 0.3397 - val_loss: 1.8498 - val_accuracy: 0.3050\n",
      "Epoch 4/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.6896 - accuracy: 0.3661\n",
      "Epoch 00004: val_accuracy improved from 0.30500 to 0.35000, saving model to /content/drive/My Drive/Models/weights.04-0.35.hdf5\n",
      "675/675 [==============================] - 703s 1s/step - loss: 1.6896 - accuracy: 0.3661 - val_loss: 1.7154 - val_accuracy: 0.3500\n",
      "Epoch 5/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.6523 - accuracy: 0.3817\n",
      "Epoch 00005: val_accuracy improved from 0.35000 to 0.38000, saving model to /content/drive/My Drive/Models/weights.05-0.38.hdf5\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.6523 - accuracy: 0.3817 - val_loss: 1.6415 - val_accuracy: 0.3800\n",
      "Epoch 6/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.6185 - accuracy: 0.3965\n",
      "Epoch 00006: val_accuracy improved from 0.38000 to 0.39625, saving model to /content/drive/My Drive/Models/weights.06-0.40.hdf5\n",
      "675/675 [==============================] - 706s 1s/step - loss: 1.6185 - accuracy: 0.3965 - val_loss: 1.6122 - val_accuracy: 0.3963\n",
      "Epoch 7/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.5882 - accuracy: 0.4123\n",
      "Epoch 00007: val_accuracy did not improve from 0.39625\n",
      "675/675 [==============================] - 708s 1s/step - loss: 1.5882 - accuracy: 0.4123 - val_loss: 1.6505 - val_accuracy: 0.3887\n",
      "Epoch 8/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.5643 - accuracy: 0.4217\n",
      "Epoch 00008: val_accuracy did not improve from 0.39625\n",
      "675/675 [==============================] - 706s 1s/step - loss: 1.5643 - accuracy: 0.4217 - val_loss: 1.7064 - val_accuracy: 0.3512\n",
      "Epoch 9/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.5402 - accuracy: 0.4399\n",
      "Epoch 00009: val_accuracy did not improve from 0.39625\n",
      "675/675 [==============================] - 707s 1s/step - loss: 1.5402 - accuracy: 0.4399 - val_loss: 2.0507 - val_accuracy: 0.2850\n",
      "Epoch 10/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.5190 - accuracy: 0.4453\n",
      "Epoch 00010: val_accuracy did not improve from 0.39625\n",
      "675/675 [==============================] - 706s 1s/step - loss: 1.5190 - accuracy: 0.4453 - val_loss: 1.6463 - val_accuracy: 0.3875\n",
      "Epoch 11/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.4925 - accuracy: 0.4583\n",
      "Epoch 00011: val_accuracy did not improve from 0.39625\n",
      "675/675 [==============================] - 707s 1s/step - loss: 1.4925 - accuracy: 0.4583 - val_loss: 1.8947 - val_accuracy: 0.2775\n",
      "Epoch 12/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.4687\n",
      "Epoch 00012: val_accuracy improved from 0.39625 to 0.44750, saving model to /content/drive/My Drive/Models/weights.12-0.45.hdf5\n",
      "675/675 [==============================] - 706s 1s/step - loss: 1.4639 - accuracy: 0.4687 - val_loss: 1.5515 - val_accuracy: 0.4475\n",
      "Epoch 13/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.4478 - accuracy: 0.4755\n",
      "Epoch 00013: val_accuracy did not improve from 0.44750\n",
      "675/675 [==============================] - 707s 1s/step - loss: 1.4478 - accuracy: 0.4755 - val_loss: 1.6428 - val_accuracy: 0.4313\n",
      "Epoch 14/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.4207 - accuracy: 0.4900\n",
      "Epoch 00014: val_accuracy did not improve from 0.44750\n",
      "675/675 [==============================] - 706s 1s/step - loss: 1.4207 - accuracy: 0.4900 - val_loss: 1.5999 - val_accuracy: 0.4212\n",
      "Epoch 15/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.4023 - accuracy: 0.4955\n",
      "Epoch 00015: val_accuracy did not improve from 0.44750\n",
      "675/675 [==============================] - 707s 1s/step - loss: 1.4023 - accuracy: 0.4955 - val_loss: 1.7686 - val_accuracy: 0.4062\n",
      "Epoch 16/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.3844 - accuracy: 0.5025\n",
      "Epoch 00016: val_accuracy did not improve from 0.44750\n",
      "675/675 [==============================] - 706s 1s/step - loss: 1.3844 - accuracy: 0.5025 - val_loss: 1.6212 - val_accuracy: 0.4475\n",
      "Epoch 17/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.3555 - accuracy: 0.5136\n",
      "Epoch 00017: val_accuracy did not improve from 0.44750\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.3555 - accuracy: 0.5136 - val_loss: 1.6548 - val_accuracy: 0.4025\n",
      "Epoch 18/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.3379 - accuracy: 0.5197\n",
      "Epoch 00018: val_accuracy improved from 0.44750 to 0.45625, saving model to /content/drive/My Drive/Models/weights.18-0.46.hdf5\n",
      "675/675 [==============================] - 707s 1s/step - loss: 1.3379 - accuracy: 0.5197 - val_loss: 1.5528 - val_accuracy: 0.4563\n",
      "Epoch 19/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.3152 - accuracy: 0.5296\n",
      "Epoch 00019: val_accuracy improved from 0.45625 to 0.46625, saving model to /content/drive/My Drive/Models/weights.19-0.47.hdf5\n",
      "675/675 [==============================] - 705s 1s/step - loss: 1.3152 - accuracy: 0.5296 - val_loss: 1.5579 - val_accuracy: 0.4663\n",
      "Epoch 20/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.3059 - accuracy: 0.5331\n",
      "Epoch 00020: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.3059 - accuracy: 0.5331 - val_loss: 1.5539 - val_accuracy: 0.4600\n",
      "Epoch 21/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.2886 - accuracy: 0.5387\n",
      "Epoch 00021: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.2886 - accuracy: 0.5387 - val_loss: 1.7052 - val_accuracy: 0.4300\n",
      "Epoch 22/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.2719 - accuracy: 0.5452\n",
      "Epoch 00022: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.2719 - accuracy: 0.5452 - val_loss: 1.6081 - val_accuracy: 0.4363\n",
      "Epoch 23/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.2513 - accuracy: 0.5526\n",
      "Epoch 00023: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.2513 - accuracy: 0.5526 - val_loss: 1.5951 - val_accuracy: 0.4338\n",
      "Epoch 24/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.2365 - accuracy: 0.5576\n",
      "Epoch 00024: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.2365 - accuracy: 0.5576 - val_loss: 1.6305 - val_accuracy: 0.4450\n",
      "Epoch 25/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.2249 - accuracy: 0.5667\n",
      "Epoch 00025: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 705s 1s/step - loss: 1.2249 - accuracy: 0.5667 - val_loss: 1.5991 - val_accuracy: 0.4563\n",
      "Epoch 26/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.2047 - accuracy: 0.5747\n",
      "Epoch 00026: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.2047 - accuracy: 0.5747 - val_loss: 1.6798 - val_accuracy: 0.4225\n",
      "Epoch 27/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.1918 - accuracy: 0.5738\n",
      "Epoch 00027: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.1918 - accuracy: 0.5738 - val_loss: 1.7175 - val_accuracy: 0.4313\n",
      "Epoch 28/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.1693 - accuracy: 0.5854\n",
      "Epoch 00028: val_accuracy did not improve from 0.46625\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.1693 - accuracy: 0.5854 - val_loss: 1.7366 - val_accuracy: 0.4425\n",
      "Epoch 29/30\n",
      "675/675 [==============================] - ETA: 0s - loss: 1.1482 - accuracy: 0.5930\n",
      "Epoch 00029: val_accuracy did not improve from 0.46625\n",
      "Restoring model weights from the end of the best epoch.\n",
      "675/675 [==============================] - 704s 1s/step - loss: 1.1482 - accuracy: 0.5930 - val_loss: 1.6306 - val_accuracy: 0.4638\n",
      "Epoch 00029: early stopping\n",
      "Evaluating model on test data...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-cc58ca8c8523>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;31m# Evaluate the model on the test data using `evaluate`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Evaluating model on test data...\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mevaluate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Test loss:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Test acc:\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_method_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_in_multi_worker_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m     \u001B[0;31m# Running inside `run_distribute_coordinator` already.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mevaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001B[0m\n\u001B[1;32m   1055\u001B[0m           \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1056\u001B[0m           \u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1057\u001B[0;31m           model=self)\n\u001B[0m\u001B[1;32m   1058\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1059\u001B[0m       \u001B[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001B[0m\n\u001B[1;32m   1097\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1099\u001B[0;31m     \u001B[0madapter_cls\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselect_data_adapter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1100\u001B[0m     self._adapter = adapter_cls(\n\u001B[1;32m   1101\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001B[0m in \u001B[0;36mselect_data_adapter\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m    961\u001B[0m         \u001B[0;34m\"Failed to find data adapter that can handle \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    962\u001B[0m         \"input: {}, {}\".format(\n\u001B[0;32m--> 963\u001B[0;31m             _type_name(x), _type_name(y)))\n\u001B[0m\u001B[1;32m    964\u001B[0m   \u001B[0;32melif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0madapter_cls\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    965\u001B[0m     raise RuntimeError(\n",
      "\u001B[0;31mValueError\u001B[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j4TQkU7x88Uv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "outputId": "ad5ea230-6219-47eb-b5b8-781522501ef1"
   },
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluating model on test data...\")\n",
    "results = model.evaluate(x_test, y_test_one_hot)\n",
    "print(\"Test loss:\", results[0])\n",
    "print(\"Test acc:\", results[1])\n",
    "\n",
    "y_test_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Classification reprot:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=8))"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Evaluating model on test data...\n",
      "25/25 [==============================] - 6s 257ms/step - loss: 1.6591 - accuracy: 0.4038\n",
      "Test loss: 1.6590604782104492\n",
      "Test acc: 0.4037500023841858\n",
      "Confusion matrix:\n",
      "[[55  3  9 14  5  9  1  4]\n",
      " [19 15 15  6 15 14  4 12]\n",
      " [ 1  6 42  0 13 32  2  4]\n",
      " [24  4  1 60  1  9  0  1]\n",
      " [ 4  9 35  1 41  9  1  0]\n",
      " [ 9  3 18  7  3 53  2  5]\n",
      " [36  6 16  6  4 21  8  3]\n",
      " [ 6 10  8  4  2 15  6 49]]\n",
      "Classification reprot:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0  0.35714286 0.55000000 0.43307087       100\n",
      "           1  0.26785714 0.15000000 0.19230769       100\n",
      "           2  0.29166667 0.42000000 0.34426230       100\n",
      "           3  0.61224490 0.60000000 0.60606061       100\n",
      "           4  0.48809524 0.41000000 0.44565217       100\n",
      "           5  0.32716049 0.53000000 0.40458015       100\n",
      "           6  0.33333333 0.08000000 0.12903226       100\n",
      "           7  0.62820513 0.49000000 0.55056180       100\n",
      "\n",
      "    accuracy                      0.40375000       800\n",
      "   macro avg  0.41321322 0.40375000 0.38819098       800\n",
      "weighted avg  0.41321322 0.40375000 0.38819098       800\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5nQETykzr9ND",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "outputId": "c34dc94d-7317-420e-a464-603a84fbe9ff"
   },
   "source": [
    "plot_history(history)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     }
    }
   ]
  }
 ]
}