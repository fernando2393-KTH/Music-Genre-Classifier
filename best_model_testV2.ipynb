{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "best_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernando2393/DT2119-Final-Project/blob/Andres_V2/best_model_testV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsm-qRxkGJTp",
        "colab_type": "code",
        "outputId": "d9867b80-500e-4870-beaf-fe395e4ae610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEzT0g7cGsjs",
        "colab_type": "code",
        "outputId": "067736de-0400-4c6f-cc8b-4b43b39507e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!rm features.py\n",
        "!rm constants.py\n",
        "!rm load_csv_data.py\n",
        "!rm loader.py\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'features.py': No such file or directory\n",
            "rm: cannot remove 'constants.py': No such file or directory\n",
            "rm: cannot remove 'load_csv_data.py': No such file or directory\n",
            "rm: cannot remove 'loader.py': No such file or directory\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hgpT66PGud1",
        "colab_type": "code",
        "outputId": "f93ce5ba-d387-4d39-dc8e-647b7e89634d",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0b21354-042f-4873-b0cc-b7a893ecee12\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d0b21354-042f-4873-b0cc-b7a893ecee12\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving constants.py to constants.py\n",
            "Saving features.py to features.py\n",
            "Saving load_csv_data.py to load_csv_data.py\n",
            "Saving loader.py to loader.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'constants.py': b'# # Run locally\\r\\n# DATASETS = \"Datasets/fma_small/\"\\r\\n# METADATA = \"Datasets/fma_metadata/\"\\r\\n# MFCC = \"Datasets/mfcc.csv\"\\r\\n# SPECTROGRAM = \"Datasets/spectrogram.csv\"\\r\\n# SPECTROGRAM_AUGMENT = \"Datasets/spectrogram_augment_1.csv\"\\r\\n# AUGMENT = True\\r\\n\\r\\n# Run on Google Colabs check that works\\r\\nDATASETS = \"/content/drive/My Drive/Datasets/fma_small/\"\\r\\nMETADATA = \"/content/drive/My Drive/Datasets/fma_metadata/\"\\r\\nMFCC = \"/content/drive/My Drive/Datasets/mfcc.csv\"\\r\\nSPECTROGRAM = \"/content/drive/My Drive/Datasets/spectrogram.csv\"\\r\\nSPECTROGRAM_AUGMENT = \"/content/drive/My Drive/Datasets/spectrogram_augment_1.csv\"\\r\\nAUGMENT = True\\r\\n\\r\\n\\r\\n',\n",
              " 'features.py': b'import pandas as pd\\r\\nimport sklearn\\r\\nimport librosa.display\\r\\nimport librosa\\r\\nimport os\\r\\nfrom tqdm import tqdm\\r\\nimport warnings\\r\\nimport constants as cts\\r\\nimport numpy as np\\r\\n\\r\\n\\r\\ndef compute_feature(mode, filepath):\\r\\n    \"\"\"\\r\\n    This method loads the a music track and computes the mfcc.\\r\\n    :param mode: allows to get either spectrogram or mfcc.\\r\\n    :param filepath: music track.\\r\\n    :return mfcc of the data track.\\r\\n    \"\"\"\\r\\n    if mode == \\'spectrogram\\':\\r\\n        y, sr = librosa.load(filepath, duration=10.5, sr=44100, mono=True, offset=0.5)  # Load 10 seconds\\r\\n        # (same length for every track)\\r\\n        stft = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))\\r\\n        mel = librosa.feature.melspectrogram(n_mels=64, sr=sr, S=stft ** 2)\\r\\n        log_mel = librosa.power_to_db(mel, ref=np.max)\\r\\n\\r\\n        return log_mel\\r\\n\\r\\n    y, sr = librosa.load(filepath, duration=28.5, sr=44100, mono=True, offset=0.5)  # Load 28 seconds\\r\\n    # (same length for every track)\\r\\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\\r\\n    mfcc = sklearn.preprocessing.scale(mfcc, axis=1)  # Normalize mfcc to have mean 0 and std 1\\r\\n\\r\\n    return mfcc\\r\\n\\r\\n\\r\\nclass FeatureComputation:\\r\\n\\r\\n    @staticmethod\\r\\n    def preprocessing(mode):\\r\\n        \"\"\"\\r\\n        This method parses the data files, calls compute_mfcc and save them into a .csv file.\\r\\n        \"\"\"\\r\\n        warnings.filterwarnings(\\'ignore\\')\\r\\n        folders = os.listdir(cts.DATASETS)\\r\\n        if \\'.DS_Store\\' in folders:  # MacOS file system check\\r\\n            folders.remove(\\'.DS_Store\\')\\r\\n        folders.sort()\\r\\n        feature_dict = {}\\r\\n        for foldername in tqdm(folders):\\r\\n            files = os.listdir(cts.DATASETS + foldername)\\r\\n            if \\'.DS_Store\\' in files:  # MacOS file system check\\r\\n                files.remove(\\'.DS_Store\\')\\r\\n            files.sort()\\r\\n            for file in files:\\r\\n                if os.path.isdir(cts.DATASETS + foldername):\\r\\n                    key = file.strip(\\'0\\')\\r\\n                    key = key.replace(\\'.mp3\\', \\'\\')\\r\\n                    feature = compute_feature(mode, cts.DATASETS + foldername + \\'/\\' + file)\\r\\n                    feature_dict[int(key)] = feature\\r\\n\\r\\n        df = pd.DataFrame(list(feature_dict.items()), columns=[\\'track\\', mode]).astype(object)\\r\\n        if mode == \\'spectrogram\\':\\r\\n            df.to_pickle(cts.SPECTROGRAM)\\r\\n        else:\\r\\n            df.to_pickle(cts.MFCC)\\r\\n\\r\\n',\n",
              " 'load_csv_data.py': b'from loader import Loader\\r\\nimport pandas as pd\\r\\n\\r\\ndef load_features(filepath):\\r\\n    return pd.read_pickle(filepath)\\r\\n\\r\\ndef get_train_val_test(filepath):\\r\\n    \"\"\"\\r\\n    :return training, validation and test datasets.\\r\\n    \"\"\"\\r\\n    loader = Loader()\\r\\n    mfcc_ = load_features(filepath)  # Load the features dataframe of the dataset songs.\\r\\n    tracks = loader.load_tracks()  # Load all the tracks of the big dataset.\\r\\n    y_train, y_val, y_test = loader.get_targets(tracks)  # Load the target values of all the tracks.\\r\\n    \\r\\n    # Get training mfcc and labels dataframes.\\r\\n    mfcc_train = mfcc_.loc[mfcc_[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    y_train = y_train[mfcc_train[\\'track\\'].to_numpy()]\\r\\n    y_train = y_train[y_train.notna()]\\r\\n    mfcc_train = mfcc_train.loc[mfcc_train[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    # Get validation mfcc and labels dataframes.\\r\\n    mfcc_val = mfcc_.loc[mfcc_[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    y_val = y_val[mfcc_val[\\'track\\'].to_numpy()]\\r\\n    y_val = y_val[y_val.notna()]\\r\\n    mfcc_val = mfcc_val.loc[mfcc_val[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    # Get testing mfcc and labels dataframes.\\r\\n    mfcc_test = mfcc_.loc[mfcc_[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    y_test = y_test[mfcc_test[\\'track\\'].to_numpy()]\\r\\n    y_test = y_test[y_test.notna()]\\r\\n    mfcc_test = mfcc_test.loc[mfcc_test[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    # Get the mfcc values and convert them to numpy arrays.\\r\\n    x_train = mfcc_train[\\'spectrogram\\'].to_numpy()\\r\\n    x_val = mfcc_val[\\'spectrogram\\'].to_numpy()\\r\\n    x_test = mfcc_test[\\'spectrogram\\'].to_numpy()\\r\\n    # Convert the target values to numpy arrays.\\r\\n    y_train = y_train.to_numpy()\\r\\n    y_val = y_val.to_numpy()\\r\\n    y_test = y_test.to_numpy()\\r\\n\\r\\n    return (x_train, y_train), (x_val, y_val), (x_test, y_test)',\n",
              " 'loader.py': b'\"\"\"\\r\\nThis class is in charge of loading the relevant data and splitting the dataset.\\r\\nnote: Check https://nbviewer.jupyter.org/github/mdeff/fma/blob/outputs/usage.ipynb for a deeper understanding of\\r\\n      the data format in the .csv files.\\r\\n\"\"\"\\r\\n\\r\\nimport pandas as pd\\r\\nimport features\\r\\nimport constants as cts\\r\\nfrom pathlib import Path\\r\\n\\r\\n\\r\\nclass Loader:\\r\\n    def __init__(self):\\r\\n        self.features = [\\'mfcc\\', \\'chroma_cens\\', \\'tonnetz\\', \\'spectral_contrast\\',\\r\\n                         [\\'spectral_centroid\\', \\'spectral_bandwidth\\', \\'spectral_rolloff\\'],\\r\\n                         [\\'rmse\\', \\'zcr\\']]  # Main categories of the stored features\\r\\n\\r\\n    @staticmethod\\r\\n    def load_echonest():\\r\\n        \"\"\"\\r\\n        This method loads the data echonest features from the .csv file.\\r\\n        :return echonest features of the data.\\r\\n        \"\"\"\\r\\n        echonest = pd.read_csv(cts.METADATA + \"echonest.csv\", index_col=0, header=[0, 1, 2])\\r\\n\\r\\n        return echonest\\r\\n\\r\\n    @staticmethod\\r\\n    def load_genres():\\r\\n        \"\"\"\\r\\n        This method loads the data genres from the .csv file.\\r\\n        :return genres of the data and top level genres.\\r\\n        \"\"\"\\r\\n        genres = pd.read_csv(cts.METADATA + \"genres.csv\", index_col=0)\\r\\n        top_level = genres[\\'top_level\\'].unique()  # This corresponds to the considered \"top-level genres\"\\r\\n\\r\\n        print(\"There is a total of \" + str(genres.shape[0]) + \" genres.\")\\r\\n        print(\"There is a total of \" + str(len(top_level)) + \" top-level genres.\")\\r\\n\\r\\n        return genres, top_level\\r\\n\\r\\n    @staticmethod\\r\\n    def load_tracks():\\r\\n        \"\"\"\\r\\n        This method loads the data tracks from the .csv file.\\r\\n        :return music tracks.\\r\\n        \"\"\"\\r\\n        tracks = pd.read_csv(cts.METADATA + \"tracks.csv\", index_col=0, header=[0, 1])\\r\\n\\r\\n        return tracks\\r\\n\\r\\n    @staticmethod\\r\\n    def load_features(mode):\\r\\n        if mode == \\'spectrogram\\':\\r\\n            if not Path(cts.SPECTROGRAM).is_file():  # Check if the file exists\\r\\n                compute_ = features.FeatureComputation()\\r\\n                compute_.preprocessing(mode)  # If the file does not exist, create it\\r\\n            mfcc_val = pd.read_pickle(cts.SPECTROGRAM)\\r\\n\\r\\n        else:\\r\\n            if not Path(cts.MFCC).is_file():  # Check if the file exists\\r\\n                compute_ = features.FeatureComputation()\\r\\n                compute_.preprocessing(mode)  # If the file does not exist, create it\\r\\n            mfcc_val = pd.read_pickle(cts.MFCC)\\r\\n\\r\\n        return mfcc_val\\r\\n\\r\\n    @staticmethod\\r\\n    def get_targets(tracks):\\r\\n        \"\"\"\\r\\n        This methods separates the tracks into dataset by means of the \\'cat\\' feature.\\r\\n        :param tracks: the music tracks loaded in the format returned by \\'load_tracks\\'.\\r\\n        :return training set, validation set and test set targets and tracks ID.\\r\\n        \"\"\"\\r\\n        train = tracks[\\'set\\', \\'split\\'] == \\'training\\'  # Training songs\\r\\n        val = tracks[\\'set\\', \\'split\\'] == \\'validation\\'  # Validation songs\\r\\n        test = tracks[\\'set\\', \\'split\\'] == \\'test\\'  # Test songs\\r\\n\\r\\n        y_train = tracks.loc[train, (\\'track\\', \\'genre_top\\')]\\r\\n        y_val = tracks.loc[val, (\\'track\\', \\'genre_top\\')]\\r\\n        y_test = tracks.loc[test, (\\'track\\', \\'genre_top\\')]\\r\\n\\r\\n        return y_train, y_val, y_test\\r\\n\\r\\n\\r\\ndef get_train_val_test(mode=\\'spectrogram\\'):\\r\\n    \"\"\"\\r\\n    :return training, validation and test datasets.\\r\\n    \"\"\"\\r\\n    loader = Loader()\\r\\n    print(\"Calculating \" + mode + \"...\")\\r\\n    mfcc_ = loader.load_features(mode)  # Load the features dataframe of the dataset songs.\\r\\n    tracks = loader.load_tracks()  # Load all the tracks of the big dataset.\\r\\n    y_train, y_val, y_test = loader.get_targets(tracks)  # Load the target values of all the tracks.\\r\\n    # Get training mfcc and labels dataframes.\\r\\n    mfcc_train = mfcc_.loc[mfcc_[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    y_train = y_train[mfcc_train[\\'track\\'].to_numpy()]\\r\\n    y_train = y_train[y_train.notna()]\\r\\n    mfcc_train = mfcc_train.loc[mfcc_train[\\'track\\'].isin(y_train.index[:].tolist())]\\r\\n    # Get validation mfcc and labels dataframes.\\r\\n    mfcc_val = mfcc_.loc[mfcc_[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    y_val = y_val[mfcc_val[\\'track\\'].to_numpy()]\\r\\n    y_val = y_val[y_val.notna()]\\r\\n    mfcc_val = mfcc_val.loc[mfcc_val[\\'track\\'].isin(y_val.index[:].tolist())]\\r\\n    # Get testing mfcc and labels dataframes.\\r\\n    mfcc_test = mfcc_.loc[mfcc_[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    y_test = y_test[mfcc_test[\\'track\\'].to_numpy()]\\r\\n    y_test = y_test[y_test.notna()]\\r\\n    mfcc_test = mfcc_test.loc[mfcc_test[\\'track\\'].isin(y_test.index[:].tolist())]\\r\\n    # Get the mfcc values and convert them to numpy arrays.\\r\\n    x_train = mfcc_train[mode].to_numpy()\\r\\n    x_val = mfcc_val[mode].to_numpy()\\r\\n    x_test = mfcc_test[mode].to_numpy()\\r\\n    # Conver the target values to numpy arrays.\\r\\n    y_train = y_train.to_numpy()\\r\\n    y_val = y_val.to_numpy()\\r\\n    y_test = y_test.to_numpy()\\r\\n\\r\\n    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\\r\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcgoALAnGvvG",
        "colab_type": "code",
        "outputId": "b3a9c21b-abd8-47de-e7f5-8e9c4a488daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import loader\n",
        "import load_csv_data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import constants\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "print(constants.METADATA)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Datasets/fma_metadata/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yv5v9cUG7YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"validation error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtUB95F9Gx0b",
        "colab_type": "code",
        "outputId": "4852c01f-c9b4-4f44-f1c6-c7f5cdc70d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load original dataset\n",
        "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram.csv\")\n",
        "print(\"There are the following classes:\")\n",
        "classes = set(y_train.tolist()) & set(y_val.tolist()) & set(y_test.tolist())\n",
        "print(classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are the following classes:\n",
            "{'International', 'Instrumental', 'Experimental', 'Rock', 'Folk', 'Pop', 'Electronic', 'Hip-Hop'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GOjdmY6GzqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load augmented dataset (different 3s of tracks sampled)\n",
        "(x_train_aug_4, y_train_aug_4), (x_val_aug_4, y_val_aug_4), (x_test_aug_4, y_test_aug_4) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_4.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nLHDJEQG1tW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load augmented dataset (time stretch, rate=0.9)\n",
        "(x_train_aug_3, y_train_aug_3), (x_val_aug_3, y_val_aug_3), (x_test_aug_3, y_test_aug_3) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_3.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0dmg67nz7DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load augmented dataset (time stretch, rate=0.9)\n",
        "(x_train_aug_2, y_train_aug_2), (x_val_aug_2, y_val_aug_2), (x_test_aug_2, y_test_aug_2) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYlZiNIr1Is2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load augmented dataset (time stretch, rate=0.9)\n",
        "#(x_train_aug_5, y_train_aug_5), (x_val_aug_5, y_val_aug_5), (x_test_aug_5, y_test_aug_5) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_5.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGXO-f2fG-uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.hstack((x_train, x_train_aug_2, x_train_aug_3, x_train_aug_4)) #, x_train_aug_5))\n",
        "#x_val = np.hstack((x_val, x_val_aug_4))\n",
        "#x_test = np.hstack((x_test, x_test_aug_4))\n",
        "y_train = np.hstack((y_train, y_train_aug_2, y_train_aug_3, y_train_aug_4)) #, y_train_aug_5))\n",
        "#y_val = np.hstack((y_val, y_val_aug_4))\n",
        "#y_test = np.hstack((y_test, y_test_aug_4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1z85QX5HB6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.rollaxis(np.dstack(x_train), -1)\n",
        "x_val = np.rollaxis(np.dstack(x_val), -1)\n",
        "x_test = np.rollaxis(np.dstack(x_test), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GO5MUBLHB9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_labels = {'Electronic': 0, 'Experimental': 1, 'Folk': 2, 'Hip-Hop': 3,\n",
        "                   'Instrumental': 4, 'International': 5, 'Pop': 6, 'Rock': 7}\n",
        "y_train = [dict_labels[y_train[i]] for i in range(y_train.shape[0])]\n",
        "y_val = [dict_labels[y_val[i]] for i in range(y_val.shape[0])]\n",
        "y_test = [dict_labels[y_test[i]] for i in range(y_test.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVmlpPyHCCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=8)\n",
        "y_val = to_categorical(y_val, num_classes=8)\n",
        "y_test = to_categorical(y_test, num_classes=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvmepsFnHIOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_val = np.expand_dims(x_val, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E27nHIQiG-DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape):\n",
        "  \"\"\"\n",
        "    model = Sequential()\n",
        "    # 1st conv layer\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 2nd conv layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 3rd conv layer\n",
        "    model.add(Conv2D(32, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # flatten output and feed it into dense layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    # output layer\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "    \"\"\"\n",
        "  \"\"\"  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(24, (3, 3), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(48, (3, 3), activation='relu', padding=\"same\"))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(48, (3, 3), activation='relu', padding=\"same\"))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  model.add(Dense(8))\n",
        "  model.add(Activation('softmax'))\n",
        "  \"\"\"\n",
        "  X_input = layers.Input(input_shape)\n",
        "\n",
        "  X = layers.Conv2D(32, (5, 5), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X1 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "  b1 = layers.MaxPool2D((2, 2))(X) \n",
        "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "  b1 = layers.Activation('relu')(b1)\n",
        "  b1 = layers.Conv2D(128, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "  X = layers.Add()([X1, b1])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X1 = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "  b1 = layers.Activation('relu')(b1)\n",
        "  b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "  X = layers.Add()([X1, b1])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "  b2 = layers.MaxPool2D((2, 2))(X) \n",
        "  b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "  b2 = layers.Activation('relu')(b2)\n",
        "  b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "\n",
        "  X = layers.Add()([X2, b2])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X2 = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "  b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "  b2 = layers.Activation('relu')(b2)\n",
        "  b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "  X = layers.Add()([X2, b2])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X3 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "  b3 = layers.MaxPool2D((2, 2))(X) \n",
        "  b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "  b3 = layers.Activation('relu')(b3)\n",
        "  b3 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "\n",
        "  X = layers.Add()([X3, b3])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  # X3 = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "  # X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "  # b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "  # b3 = layers.BatchNormalization()(b3)\n",
        "  # b3 = layers.Activation('relu')(b3)\n",
        "  # b3 = layers.Conv2D(128, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "  # b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "  # X = layers.Add()([X3, b3])\n",
        "  # X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  print(\"Pre-RELU\",X.shape)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  print(\"Pre-MaxPool2D\",X.shape)\n",
        "  X = layers.MaxPool2D((2, 2))(X)\n",
        "  print(\"Post-MaxPool2D\",X.shape)\n",
        "\n",
        "  # Dense Layers\n",
        "  print(\"Pre-Flatten\",X.shape)\n",
        "  X = layers.Flatten()(X)\n",
        "  # print(\"Pre-Dense\",X.shape)\n",
        "  # X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
        "  # print(\"Post-Dense\",X.shape)\n",
        "  # X = layers.BatchNormalization()(X)\n",
        "  # X = layers.Activation('relu')(X)\n",
        "  X = tfa.layers.Maxout(int(X.shape[1]/128))(X)\n",
        "  X = Dropout(0.4)(X)\n",
        "\n",
        "  # Global PoolingK\n",
        "  # print(\"Pre-GlobalAveragePooling2D\",X.shape)\n",
        "  # X = layers.GlobalAveragePooling2D()(X)\n",
        "\n",
        "  # Output Layer\n",
        "  # print(\"Pre-Output\",X.shape)\n",
        "  # X = layers.Dense(8, kernel_initializer='he_uniform', kernel_regularizer=tf.keras.regularizers.l2(0.01))(X)\n",
        "  # print(\"Post-Output\",X.shape)\n",
        "  # X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('softmax')(X)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=X_input, outputs=X, name='model_8')\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W69-quhWHIUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfe25e3d-d634-4588-8ee9-5d1d6c9a058f"
      },
      "source": [
        "lr = 2e-4\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "\n",
        "model = build_model((128, 128, 1))\n",
        "opt = Adam(lr=lr, decay=lr / epochs)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Callbacks: early stopping and checkpoint\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1,\n",
        "                               patience=10,\n",
        "                               mode='max',\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "filepath = \"weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "callbacks_list = [early_stopping, checkpoint]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre-RELU (None, 8, 8, 64)\n",
            "Pre-MaxPool2D (None, 8, 8, 64)\n",
            "Post-MaxPool2D (None, 4, 4, 64)\n",
            "Pre-Flatten (None, 4, 4, 64)\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 64, 64, 32)   832         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 64, 64, 32)   128         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 64, 64, 32)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 32, 32, 32)   0           activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 32, 32, 16)   528         max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 32, 32, 16)   64          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 16)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 32, 32, 128)  2176        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 32, 32, 128)  36992       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 32, 32, 128)  512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 32, 32, 128)  512         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 16)   2064        batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 128)  0           batch_normalization_38[0][0]     \n",
            "                                                                 batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 32, 32, 16)   64          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 128)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 16)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 256)  295168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 256)  4352        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 32, 32, 256)  1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 32, 32, 256)  1024        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 256)  0           batch_normalization_41[0][0]     \n",
            "                                                                 batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 256)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 16, 16, 32)   8224        max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 16, 16, 32)   128         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 32)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 16, 16, 512)  16896       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 16, 16, 512)  1180160     activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 16, 16, 512)  2048        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 16, 16, 512)  2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 16, 16, 32)   16416       batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 512)  0           batch_normalization_44[0][0]     \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 16, 16, 32)   128         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 512)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 16, 16, 512)  2359808     activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 16, 16, 512)  16896       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 16, 16, 512)  2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 16, 16, 512)  2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 512)  0           batch_normalization_47[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 512)  0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 8, 8, 512)    0           activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 8, 8, 64)     32832       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 64)     256         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 8, 8, 512)    2359808     activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 8, 8, 512)    33280       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 8, 8, 512)    2048        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 512)    2048        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 512)    0           batch_normalization_50[0][0]     \n",
            "                                                                 batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 512)    0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 8, 8, 64)     294976      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 64)     256         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 64)     0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 4, 4, 64)     0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1024)         0           max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "maxout_2 (Maxout)               (None, 8)            0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 8)            0           maxout_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8)            0           dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 6,677,792\n",
            "Trainable params: 6,669,600\n",
            "Non-trainable params: 8,192\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRGXNeFraB8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5092d685-e8ce-479c-c054-9f6888c6b89e"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    callbacks=callbacks_list,\n",
        "                    epochs=epochs, verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.3931 - accuracy: 0.2597\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.37125, saving model to weights.01-0.37.hdf5\n",
            "1598/1598 [==============================] - 66s 41ms/step - loss: 0.3931 - accuracy: 0.2597 - val_loss: 0.3379 - val_accuracy: 0.3713\n",
            "Epoch 2/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.3537 - accuracy: 0.3078\n",
            "Epoch 00002: val_accuracy improved from 0.37125 to 0.41375, saving model to weights.02-0.41.hdf5\n",
            "1598/1598 [==============================] - 67s 42ms/step - loss: 0.3537 - accuracy: 0.3078 - val_loss: 0.3281 - val_accuracy: 0.4137\n",
            "Epoch 3/30\n",
            "1598/1598 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.3317\n",
            "Epoch 00003: val_accuracy improved from 0.41375 to 0.46750, saving model to weights.03-0.47.hdf5\n",
            "1598/1598 [==============================] - 68s 43ms/step - loss: 0.3440 - accuracy: 0.3317 - val_loss: 0.3166 - val_accuracy: 0.4675\n",
            "Epoch 4/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.3367 - accuracy: 0.3402\n",
            "Epoch 00004: val_accuracy improved from 0.46750 to 0.47375, saving model to weights.04-0.47.hdf5\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.3367 - accuracy: 0.3402 - val_loss: 0.3110 - val_accuracy: 0.4737\n",
            "Epoch 5/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.3295 - accuracy: 0.3523\n",
            "Epoch 00005: val_accuracy improved from 0.47375 to 0.47625, saving model to weights.05-0.48.hdf5\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.3295 - accuracy: 0.3523 - val_loss: 0.3070 - val_accuracy: 0.4762\n",
            "Epoch 6/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.3222 - accuracy: 0.3706\n",
            "Epoch 00006: val_accuracy did not improve from 0.47625\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.3222 - accuracy: 0.3706 - val_loss: 0.3080 - val_accuracy: 0.4688\n",
            "Epoch 7/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.3801\n",
            "Epoch 00007: val_accuracy did not improve from 0.47625\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.3159 - accuracy: 0.3803 - val_loss: 0.3082 - val_accuracy: 0.4675\n",
            "Epoch 8/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.3980\n",
            "Epoch 00008: val_accuracy did not improve from 0.47625\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.3073 - accuracy: 0.3981 - val_loss: 0.3181 - val_accuracy: 0.4475\n",
            "Epoch 9/30\n",
            "1598/1598 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.4131\n",
            "Epoch 00009: val_accuracy improved from 0.47625 to 0.50375, saving model to weights.09-0.50.hdf5\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.2992 - accuracy: 0.4131 - val_loss: 0.2958 - val_accuracy: 0.5038\n",
            "Epoch 10/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.2900 - accuracy: 0.4289\n",
            "Epoch 00010: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.2900 - accuracy: 0.4288 - val_loss: 0.2990 - val_accuracy: 0.4750\n",
            "Epoch 11/30\n",
            "1598/1598 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.4475\n",
            "Epoch 00011: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.2799 - accuracy: 0.4475 - val_loss: 0.2964 - val_accuracy: 0.4837\n",
            "Epoch 12/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.4747\n",
            "Epoch 00012: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.2655 - accuracy: 0.4746 - val_loss: 0.2999 - val_accuracy: 0.4725\n",
            "Epoch 13/30\n",
            "1598/1598 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 0.4848\n",
            "Epoch 00013: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 69s 43ms/step - loss: 0.2568 - accuracy: 0.4848 - val_loss: 0.3249 - val_accuracy: 0.4525\n",
            "Epoch 14/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.5125\n",
            "Epoch 00014: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.2424 - accuracy: 0.5124 - val_loss: 0.2948 - val_accuracy: 0.4775\n",
            "Epoch 15/30\n",
            "1598/1598 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.5297\n",
            "Epoch 00015: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.2299 - accuracy: 0.5297 - val_loss: 0.3039 - val_accuracy: 0.4638\n",
            "Epoch 16/30\n",
            "1598/1598 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.5401\n",
            "Epoch 00016: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.2221 - accuracy: 0.5401 - val_loss: 0.3177 - val_accuracy: 0.4475\n",
            "Epoch 17/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.5574\n",
            "Epoch 00017: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.2106 - accuracy: 0.5573 - val_loss: 0.2922 - val_accuracy: 0.5013\n",
            "Epoch 18/30\n",
            "1597/1598 [============================>.] - ETA: 0s - loss: 0.2015 - accuracy: 0.5699\n",
            "Epoch 00018: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.2015 - accuracy: 0.5699 - val_loss: 0.3218 - val_accuracy: 0.3963\n",
            "Epoch 19/30\n",
            "1598/1598 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.5769Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.50375\n",
            "1598/1598 [==============================] - 70s 44ms/step - loss: 0.1949 - accuracy: 0.5769 - val_loss: 0.3136 - val_accuracy: 0.4525\n",
            "Epoch 00019: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcmfjxu1aGVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a284f431-fe41-40cb-f2dd-cc6b85161985"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NqhLE0EOV9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "804661da-e5f7-4a41-c82c-f104b0c8a89f"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluating model on test data...\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test acc:\", results[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on test data...\n",
            "50/50 [==============================] - 1s 13ms/step - loss: 0.3245 - accuracy: 0.4025\n",
            "Test loss: 0.32447579503059387\n",
            "Test acc: 0.4025000035762787\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}