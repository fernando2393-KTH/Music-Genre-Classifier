{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7YHtb+9SWu8846Gk3OERA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernando2393/DT2119-Final-Project/blob/Maria/best_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsm-qRxkGJTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "91c477fc-b2e6-49e8-dd94-728c31baf6ea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEzT0g7cGsjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm features.py\n",
        "#!rm constants.py\n",
        "#!rm load_csv_data.py\n",
        "#!rm loader.py\n",
        "#!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hgpT66PGud1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcgoALAnGvvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import loader\n",
        "import load_csv_data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtUB95F9Gx0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52a29a6d-8644-4dc4-ac1d-c17de8681b2a"
      },
      "source": [
        "# Load original dataset\n",
        "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram.csv\")\n",
        "print(\"There are the following classes:\")\n",
        "classes = set(y_train.tolist()) & set(y_val.tolist()) & set(y_test.tolist())\n",
        "print(classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are the following classes:\n",
            "{'Hip-Hop', 'Pop', 'Experimental', 'Folk', 'Electronic', 'International', 'Instrumental', 'Rock'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GOjdmY6GzqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0807e5b7-1d46-4dba-ea5d-968c18aaf900"
      },
      "source": [
        "# Load augmented dataset (different 3s of tracks sampled)\n",
        "(x_train_aug_4, y_train_aug_4), (x_val_aug_4, y_val_aug_4), (x_test_aug_4, y_test_aug_4) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_4.csv\")\n",
        "print(\"There are the following classes:\")\n",
        "classes = set(y_train_aug_4.tolist()) & set(y_val_aug_4.tolist()) & set(y_test_aug_4.tolist())\n",
        "print(classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are the following classes:\n",
            "{'Hip-Hop', 'Pop', 'Experimental', 'Folk', 'Electronic', 'International', 'Instrumental', 'Rock'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nLHDJEQG1tW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load augmented dataset (time stretch, rate=0.9)\n",
        "(x_train_aug_3, y_train_aug_3), (x_val_aug_3, y_val_aug_3), (x_test_aug_3, y_test_aug_3) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_3.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI5Da2IcG4OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_layer(inputs, filters, kernel_size, pool_size):\n",
        "    x = Conv1D(filters, kernel_size)(inputs)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = MaxPooling1D(pool_size=pool_size, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class Classifier:\n",
        "\n",
        "    @staticmethod\n",
        "    def build(inputs, classes, layers, filters, kernel_size, pool_size):\n",
        "        # Convolutional layers\n",
        "        x = inputs\n",
        "        for i in range(layers):\n",
        "            x = conv_layer(x, filters[i], kernel_size[i], pool_size[i])\n",
        "        x = tf.keras.layers.LSTM(96, return_sequences=False)(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        # Final layer\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(), activation='relu')(x)\n",
        "        x = Dropout(rate=0.4, trainable=True)(x)\n",
        "        outputs = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "        return tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yv5v9cUG7YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"validation error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E27nHIQiG-DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape):\n",
        "  \"\"\"\n",
        "    model = Sequential()\n",
        "    # 1st conv layer\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 2nd conv layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 3rd conv layer\n",
        "    model.add(Conv2D(32, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # flatten output and feed it into dense layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    # output layer\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "    \"\"\"\n",
        "  \"\"\"  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(24, (3, 3), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(48, (3, 3), activation='relu', padding=\"same\"))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(48, (3, 3), activation='relu', padding=\"same\"))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  model.add(Dense(8))\n",
        "  model.add(Activation('softmax'))\n",
        "  \"\"\"\n",
        "  X_input = layers.Input(input_shape)\n",
        "\n",
        "  X = layers.Conv2D(32, (5, 5), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X1 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "  b1 = layers.MaxPool2D((2, 2))(X) \n",
        "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "  b1 = layers.Activation('relu')(b1)\n",
        "  b1 = layers.Conv2D(128, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "  X = layers.Add()([X1, b1])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X1 = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "  b1 = layers.Activation('relu')(b1)\n",
        "  b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "  X = layers.Add()([X1, b1])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X2 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "  b2 = layers.MaxPool2D((2,2))(X) \n",
        "  b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "  b2 = layers.Activation('relu')(b2)\n",
        "  b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "\n",
        "  X = layers.Add()([X2, b2])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X2 = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "  b2 = layers.Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "  b2 = layers.Activation('relu')(b2)\n",
        "  b2 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "  X = layers.Add()([X2, b2])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X3 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "  b3 = layers.MaxPool2D((2,2))(X) \n",
        "  b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "  b3 = layers.Activation('relu')(b3)\n",
        "  b3 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "\n",
        "  X = layers.Add()([X3, b3])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X3 = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "  b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "  b3 = layers.Activation('relu')(b3)\n",
        "  b3 = layers.Conv2D(128, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "  X = layers.Add()([X3, b3])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = layers.MaxPool2D(2, 2)(X)\n",
        "\n",
        "  X = layers.Flatten()(X)\n",
        "  X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = layers.Dense(8,kernel_initializer='he_uniform')(X)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('softmax')(X)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=X_input, outputs=X, name='model_8')\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGXO-f2fG-uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.hstack((x_train, x_train_aug_3, x_train_aug_4))\n",
        "#x_val = np.hstack((x_val, x_val_aug_4))\n",
        "#x_test = np.hstack((x_test, x_test_aug_4))\n",
        "y_train = np.hstack((y_train, y_train_aug_3, y_train_aug_4))\n",
        "#y_val = np.hstack((y_val, y_val_aug_4))\n",
        "#y_test = np.hstack((y_test, y_test_aug_4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1z85QX5HB6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.rollaxis(np.dstack(x_train), -1)\n",
        "x_val = np.rollaxis(np.dstack(x_val), -1)\n",
        "x_test = np.rollaxis(np.dstack(x_test), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GO5MUBLHB9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_labels = {'Electronic': 0, 'Experimental': 1, 'Folk': 2, 'Hip-Hop': 3,\n",
        "                   'Instrumental': 4, 'International': 5, 'Pop': 6, 'Rock': 7}\n",
        "y_train = [dict_labels[y_train[i]] for i in range(y_train.shape[0])]\n",
        "y_val = [dict_labels[y_val[i]] for i in range(y_val.shape[0])]\n",
        "y_test = [dict_labels[y_test[i]] for i in range(y_test.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVmlpPyHCCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=8)\n",
        "y_val = to_categorical(y_val, num_classes=8)\n",
        "y_test = to_categorical(y_test, num_classes=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvmepsFnHIOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_val = np.expand_dims(x_val, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W69-quhWHIUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9173ef9-beab-4aa8-ec0f-907d22b97c04"
      },
      "source": [
        "lr = 2e-4\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "\n",
        "model = build_model((128, 128, 1))\n",
        "opt = Adam(lr=lr, decay=lr / epochs)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Callbacks: early stopping and checkpoint\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1,\n",
        "                               patience=10,\n",
        "                               mode='max',\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "filepath = \"weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "callbacks_list = [early_stopping, checkpoint]\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    callbacks=callbacks_list,\n",
        "                    epochs=epochs, verbose=1)\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 64, 64, 32)   832         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 64, 64, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 64, 64, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 32)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   528         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 128)  2176        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 128)  36992       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2064        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 128)  0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  295168      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 256)  4352        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   8224        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 512)  16896       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 512)  1180160     activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   16416       batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 512)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  2359808     activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  16896       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 512)    0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 64)     32832       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 512)    33280       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 512)    2359808     activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 512)    2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     32832       batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 128)    589952      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 128)    8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 128)    0           batch_normalization_16[0][0]     \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     73792       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          131200      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 128)          512         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 128)          0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 8)            1032        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8)            32          dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8)            0           batch_normalization_21[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 7,221,768\n",
            "Trainable params: 7,212,664\n",
            "Non-trainable params: 9,104\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "1198/1198 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.4007\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.39375, saving model to weights.01-0.39.hdf5\n",
            "1198/1198 [==============================] - 51s 43ms/step - loss: 0.3125 - accuracy: 0.4007 - val_loss: 0.3145 - val_accuracy: 0.3938\n",
            "Epoch 2/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.4859\n",
            "Epoch 00002: val_accuracy improved from 0.39375 to 0.42125, saving model to weights.02-0.42.hdf5\n",
            "1198/1198 [==============================] - 53s 44ms/step - loss: 0.2816 - accuracy: 0.4858 - val_loss: 0.3133 - val_accuracy: 0.4212\n",
            "Epoch 3/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.5245\n",
            "Epoch 00003: val_accuracy improved from 0.42125 to 0.46500, saving model to weights.03-0.47.hdf5\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.2668 - accuracy: 0.5246 - val_loss: 0.3110 - val_accuracy: 0.4650\n",
            "Epoch 4/30\n",
            "1198/1198 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.5584\n",
            "Epoch 00004: val_accuracy improved from 0.46500 to 0.50750, saving model to weights.04-0.51.hdf5\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.2514 - accuracy: 0.5584 - val_loss: 0.2770 - val_accuracy: 0.5075\n",
            "Epoch 5/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.2358 - accuracy: 0.5927\n",
            "Epoch 00005: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 43ms/step - loss: 0.2358 - accuracy: 0.5929 - val_loss: 0.2888 - val_accuracy: 0.4712\n",
            "Epoch 6/30\n",
            "1198/1198 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.6461\n",
            "Epoch 00006: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 43ms/step - loss: 0.2151 - accuracy: 0.6461 - val_loss: 0.3067 - val_accuracy: 0.4800\n",
            "Epoch 7/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.1872 - accuracy: 0.7135\n",
            "Epoch 00007: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.1872 - accuracy: 0.7135 - val_loss: 0.3076 - val_accuracy: 0.4588\n",
            "Epoch 8/30\n",
            "1198/1198 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.7799\n",
            "Epoch 00008: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.1574 - accuracy: 0.7799 - val_loss: 0.3394 - val_accuracy: 0.4425\n",
            "Epoch 9/30\n",
            "1198/1198 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.8310\n",
            "Epoch 00009: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.1323 - accuracy: 0.8310 - val_loss: 0.3075 - val_accuracy: 0.4837\n",
            "Epoch 10/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.1148 - accuracy: 0.8618\n",
            "Epoch 00010: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.1148 - accuracy: 0.8618 - val_loss: 0.3397 - val_accuracy: 0.4050\n",
            "Epoch 11/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.8830\n",
            "Epoch 00011: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.1014 - accuracy: 0.8828 - val_loss: 0.3143 - val_accuracy: 0.4688\n",
            "Epoch 12/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.0916 - accuracy: 0.9010\n",
            "Epoch 00012: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.0916 - accuracy: 0.9010 - val_loss: 0.3335 - val_accuracy: 0.4588\n",
            "Epoch 13/30\n",
            "1198/1198 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.9100\n",
            "Epoch 00013: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.0831 - accuracy: 0.9100 - val_loss: 0.3410 - val_accuracy: 0.4450\n",
            "Epoch 14/30\n",
            "1197/1198 [============================>.] - ETA: 0s - loss: 0.0782 - accuracy: 0.9174Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.50750\n",
            "1198/1198 [==============================] - 52s 44ms/step - loss: 0.0782 - accuracy: 0.9174 - val_loss: 0.3429 - val_accuracy: 0.4250\n",
            "Epoch 00014: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NqhLE0EOV9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "58dc091d-0739-49ee-86e4-cf05b6267d6b"
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluating model on test data...\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test acc:\", results[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model on test data...\n",
            "50/50 [==============================] - 1s 12ms/step - loss: 0.3074 - accuracy: 0.4613\n",
            "Test loss: 0.3073626756668091\n",
            "Test acc: 0.4612500071525574\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}