{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMoBRImb+Jysf1WwvdAuYwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernando2393/DT2119-Final-Project/blob/Maria/best_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsm-qRxkGJTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c368b25f-8036-4181-cdc8-0c35166a49c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEzT0g7cGsjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm features.py\n",
        "#!rm constants.py\n",
        "#!rm load_csv_data.py\n",
        "#!rm loader.py\n",
        "#!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hgpT66PGud1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcgoALAnGvvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import loader\n",
        "import load_csv_data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtUB95F9Gx0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "047dc139-2384-4305-936a-a6bcbab75858"
      },
      "source": [
        "# Load original dataset\n",
        "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram.csv\")\n",
        "print(\"There are the following classes:\")\n",
        "classes = set(y_train.tolist()) & set(y_val.tolist()) & set(y_test.tolist())\n",
        "print(classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are the following classes:\n",
            "{'Hip-Hop', 'Pop', 'Folk', 'International', 'Instrumental', 'Electronic', 'Experimental', 'Rock'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GOjdmY6GzqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "49dc14b5-61fd-4b4a-d0d2-a16b63445aff"
      },
      "source": [
        "# Load augmented dataset (different 3s of tracks sampled)\n",
        "(x_train_aug_4, y_train_aug_4), (x_val_aug_4, y_val_aug_4), (x_test_aug_4, y_test_aug_4) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_4.csv\")\n",
        "print(\"There are the following classes:\")\n",
        "classes = set(y_train_aug_4.tolist()) & set(y_val_aug_4.tolist()) & set(y_test_aug_4.tolist())\n",
        "print(classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are the following classes:\n",
            "{'Hip-Hop', 'Pop', 'Folk', 'International', 'Instrumental', 'Electronic', 'Experimental', 'Rock'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nLHDJEQG1tW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load augmented dataset (time stretch, rate=0.9)\n",
        "(x_train_aug_3, y_train_aug_3), (x_val_aug_3, y_val_aug_3), (x_test_aug_3, y_test_aug_3) = load_csv_data.get_train_val_test(\"/content/drive/My Drive/Datasets/spectrogram_augment_3.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI5Da2IcG4OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_layer(inputs, filters, kernel_size, pool_size):\n",
        "    x = Conv1D(filters, kernel_size)(inputs)\n",
        "    x = tf.nn.relu(x)\n",
        "    x = MaxPooling1D(pool_size=pool_size, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class Classifier:\n",
        "\n",
        "    @staticmethod\n",
        "    def build(inputs, classes, layers, filters, kernel_size, pool_size):\n",
        "        # Convolutional layers\n",
        "        x = inputs\n",
        "        for i in range(layers):\n",
        "            x = conv_layer(x, filters[i], kernel_size[i], pool_size[i])\n",
        "        x = tf.keras.layers.LSTM(96, return_sequences=False)(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        # Final layer\n",
        "        x = Flatten()(x)\n",
        "        x = Dense(64, kernel_regularizer=tf.keras.regularizers.l2(), activation='relu')(x)\n",
        "        x = Dropout(rate=0.4, trainable=True)(x)\n",
        "        outputs = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "        return tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yv5v9cUG7YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"validation error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E27nHIQiG-DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(input_shape):\n",
        "  \"\"\"\n",
        "    model = Sequential()\n",
        "    # 1st conv layer\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 2nd conv layer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # 3rd conv layer\n",
        "    model.add(Conv2D(32, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    # flatten output and feed it into dense layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    # output layer\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "    \"\"\"\n",
        "  \"\"\"  \n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(24, (3, 3), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(48, (3, 3), activation='relu', padding=\"same\"))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv2D(48, (3, 3), activation='relu', padding=\"same\"))\n",
        "  model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  model.add(Dense(8))\n",
        "  model.add(Activation('softmax'))\n",
        "  \"\"\"\n",
        "  X_input = layers.Input(input_shape)\n",
        "\n",
        "  X = layers.Conv2D(32, (5, 5), strides=(2, 2), padding = 'same', kernel_initializer='he_uniform')(X_input)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X1 = layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "  b1 = layers.MaxPool2D((2, 2))(X) \n",
        "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "  b1 = layers.Activation('relu')(b1)\n",
        "  b1 = layers.Conv2D(128, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "  X = layers.Add()([X1, b1])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X1 = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X1 = layers.BatchNormalization()(X1)\n",
        "\n",
        "  b1 = layers.Conv2D(16, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "  b1 = layers.Activation('relu')(b1)\n",
        "  b1 = layers.Conv2D(256, (1, 1), padding='same', kernel_initializer='he_uniform')(b1)\n",
        "  b1 = layers.BatchNormalization()(b1)\n",
        "\n",
        "  X = layers.Add()([X1, b1])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X2 = layers.Conv2D(512, (1, 5), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "  b2 = layers.MaxPool2D((2, 2))(X) \n",
        "  b2 = layers.Conv2D(32, (1, 5), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "  b2 = layers.Activation('relu')(b2)\n",
        "  b2 = layers.Conv2D(512, (1, 5), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "\n",
        "  X = layers.Add()([X2, b2])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X2 = layers.Conv2D(512, (5, 1), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X2 = layers.BatchNormalization()(X2)\n",
        "\n",
        "  b2 = layers.Conv2D(32, (5, 1), padding='same', kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "  b2 = layers.Activation('relu')(b2)\n",
        "  b2 = layers.Conv2D(512, (5, 1), padding='same',  kernel_initializer='he_uniform')(b2)\n",
        "  b2 = layers.BatchNormalization()(b2)\n",
        "\n",
        "  X = layers.Add()([X2, b2])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X3 = layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "  b3 = layers.MaxPool2D((2,2))(X) \n",
        "  b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "  b3 = layers.Activation('relu')(b3)\n",
        "  b3 = layers.Conv2D(512, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "\n",
        "  X = layers.Add()([X3, b3])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X3 = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_normal')(X)\n",
        "  X3 = layers.BatchNormalization()(X3)\n",
        "\n",
        "  b3 = layers.Conv2D(64, (1, 1), padding='same', kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "  b3 = layers.Activation('relu')(b3)\n",
        "  b3 = layers.Conv2D(128, (1, 1), padding='same',  kernel_initializer='he_uniform')(b3)\n",
        "  b3 = layers.BatchNormalization()(b3)\n",
        "\n",
        "  X = layers.Add()([X3, b3])\n",
        "  X = layers.Activation('relu')(X)\n",
        "\n",
        "  X = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(X)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = layers.MaxPool2D(2, 2)(X)\n",
        "\n",
        "  X = layers.Flatten()(X)\n",
        "  X = layers.Dense(128, kernel_initializer='he_uniform')(X)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('relu')(X)\n",
        "  X = layers.Dense(8,kernel_initializer='he_uniform')(X)\n",
        "  X = layers.BatchNormalization()(X)\n",
        "  X = layers.Activation('softmax')(X)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs=X_input, outputs=X, name='model_8')\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGXO-f2fG-uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.hstack((x_train, x_train_aug_3, x_train_aug_4))\n",
        "#x_val = np.hstack((x_val, x_val_aug_4))\n",
        "#x_test = np.hstack((x_test, x_test_aug_4))\n",
        "y_train = np.hstack((y_train, y_train_aug_3, y_train_aug_4))\n",
        "#y_val = np.hstack((y_val, y_val_aug_4))\n",
        "#y_test = np.hstack((y_test, y_test_aug_4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1z85QX5HB6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.rollaxis(np.dstack(x_train), -1)\n",
        "x_val = np.rollaxis(np.dstack(x_val), -1)\n",
        "x_test = np.rollaxis(np.dstack(x_test), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GO5MUBLHB9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_labels = {'Electronic': 0, 'Experimental': 1, 'Folk': 2, 'Hip-Hop': 3,\n",
        "                   'Instrumental': 4, 'International': 5, 'Pop': 6, 'Rock': 7}\n",
        "y_train = [dict_labels[y_train[i]] for i in range(y_train.shape[0])]\n",
        "y_val = [dict_labels[y_val[i]] for i in range(y_val.shape[0])]\n",
        "y_test = [dict_labels[y_test[i]] for i in range(y_test.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVmlpPyHCCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=8)\n",
        "y_val = to_categorical(y_val, num_classes=8)\n",
        "y_test = to_categorical(y_test, num_classes=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvmepsFnHIOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_val = np.expand_dims(x_val, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W69-quhWHIUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b4afa46-61d2-4c6b-871f-91bb3d5a5857"
      },
      "source": [
        "lr = 2e-4\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "\n",
        "model = build_model((128, 128, 1))\n",
        "opt = Adam(lr=lr, decay=lr / epochs)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "#model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Callbacks: early stopping and checkpoint\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1,\n",
        "                               patience=10,\n",
        "                               mode='max',\n",
        "                               restore_best_weights=True)\n",
        "\n",
        "filepath = \"weights.{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "callbacks_list = [early_stopping, checkpoint]\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    callbacks=callbacks_list,\n",
        "                    epochs=epochs, verbose=1)\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 64, 64, 32)   832         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 64, 64, 32)   128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 64, 64, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 32, 32, 32)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   528         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 128)  2176        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 128)  36992       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 128)  512         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2064        batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 128)  0           batch_normalization_1[0][0]      \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 128)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 256)  295168      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 256)  4352        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 256)  0           batch_normalization_4[0][0]      \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 256)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   40992       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 512)  82432       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 512)  655872      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   81952       batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 512)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 512)  1311232     activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  82432       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 512)    0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 64)     32832       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 64)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 512)    33280       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 512)    2359808     activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 512)    2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 512)    2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     32832       batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 512)    0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 128)    589952      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 128)    8320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 128)    512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 128)    512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 128)    0           batch_normalization_16[0][0]     \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     73792       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 64)     0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 1024)         0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          131200      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 128)          512         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 128)          0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 8)            1032        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8)            32          dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8)            0           batch_normalization_21[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 5,878,280\n",
            "Trainable params: 5,869,176\n",
            "Non-trainable params: 9,104\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NqhLE0EOV9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the model on the test data using `evaluate`\n",
        "print(\"Evaluating model on test data...\")\n",
        "results = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test acc:\", results[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}